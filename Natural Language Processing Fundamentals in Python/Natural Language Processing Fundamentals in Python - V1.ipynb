{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regular expressions & word tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to regular expressions - Video"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Which pattern?\n",
    "50xp\n",
    "Which of the following Regex patterns result in the following text?\n",
    "\n",
    "`>>> my_string = \"Let's write RegEx!\"\n",
    "`>>> re.findall(PATTERN, my_string)`\n",
    "['Let', 's', 'write', 'RegEx']`\n",
    "\n",
    "Possible Answers\n",
    "Click or Press Ctrl+1 to focus\n",
    "PATTERN = r\"\\s+\"\n",
    "PATTERN = r\"\\w+\" (Correct)\n",
    "PATTERN = r\"[a-z]\"\n",
    "PATTERN = r\"\\w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', 's', 'write', 'RegEx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"Let's write RegEx!\"\n",
    "PATTERN = r\"\\w+\" \n",
    "re.findall(PATTERN, my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing regular expressions: re.split() and re.findall()\n",
    "\n",
    "Now you'll get a chance to write some regular expressions to match digits, strings and non-alphanumeric characters. Take a look at my_string first by printing it in the IPython Shell, to determine how you might best match the different steps.\n",
    "\n",
    "Note: It's important to prefix your regex patterns with r to ensure that your patterns are interpreted in the way you want them to. Else, you may encounter problems to do with escape sequences in strings. For example, \"/n\" in Python is used to indicate a new line, but if you use the r prefix, it will be interpreted as \"/n\".\n",
    "\n",
    "Instructions\n",
    " - Import the regular expression module re.\n",
    " - Split my_string on each sentence ending. To do this:\n",
    "     - Write a pattern called sentence_endings to match sentence endings (., !, and ?).\n",
    "     - Use re.split() to split my_string on the pattern and print the result.\n",
    " - Find all capitalized words in my_string by writing a pattern called capitalized_words and using re.findall(). Print the result.\n",
    " - Write a pattern called spaces to match spaces and then use re.split() to split my_string on this pattern, keeping all punctuation intact. Print the result.\n",
    " - Find all digits in my_string by writing a pattern called digits and using re.findall(). Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_string = \"Let's write RegEx!  Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's write RegEx\", \"  Won't that be fun\", '  I sure think so', '  Can you find 4 sentences', '  Or perhaps, all 19 words', '']\n",
      "['Let', 'RegEx', 'Won', 'Can', 'Or']\n",
      "[\"Let's\", 'write', 'RegEx!', \"Won't\", 'that', 'be', 'fun?', 'I', 'sure', 'think', 'so.', 'Can', 'you', 'find', '4', 'sentences?', 'Or', 'perhaps,', 'all', '19', 'words?']\n",
      "['4', '19']\n"
     ]
    }
   ],
   "source": [
    "# Import the regex module\n",
    "import re\n",
    "\n",
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "sentence_endings = r\"[.!?]\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(sentence_endings, my_string))\n",
    "\n",
    "# Find all capitalized words in my_string and print the result\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, my_string))\n",
    "\n",
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces, my_string))\n",
    "\n",
    "# Find all digits in my_string and print the result\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, my_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's\", 'RegEx', \"Won't\", 'Can', 'Or']\n"
     ]
    }
   ],
   "source": [
    "capitalized_words = r\"[A-Z][\\w']+\"\n",
    "print(re.findall(capitalized_words, my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to tokenization - Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene_one = \"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tokenization with NLTK\n",
    "\n",
    "Here, you'll be using the first scene of Monty Python's Holy Grail, which has been pre-loaded as scene_one. You will have access to word_tokenize and sent_tokenize from the nltk.tokenize library. You can utilize them to tokenize both words and sentences from Python strings.\n",
    "\n",
    "Instructions\n",
    " - Import the sent_tokenize and word_tokenize functions from nltk.tokenize.\n",
    " - Tokenize all the sentences in scene_one.\n",
    " - Tokenize the fourth sentence in sentences.\n",
    " - Find the unique tokens in the entire scene by using word_tokenize() on scene_one and then converting it into a set.\n",
    " - Print the unique tokens found. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'who', 'Camelot', 'breadth', 'and', 'Ridden', 'am', \"'em\", 'second', 'got', 'minute', 'use', 'kingdom', 'under', 'may', 'speak', 'Who', 'south', 'wind', 'there', 'King', '...', 'they', 'bangin', 'Uther', 'Pull', 'That', 'all', 'these', 'you', 'swallows', 'wings', \"'d\", 'SCENE', 'Where', 'do', 'order', 'one', 'Am', 'A', 'them', 'are', 'he', 'European', 'master', 'carry', 'defeator', ':', 'needs', 'Supposing', 'In', 'Will', 'my', 'So', 'carried', 'pound', 'not', 'ratios', 'Found', 'sovereign', 'Please', 'yet', 'snows', 'Listen', 'in', '2', 'agree', 'ask', 'knights', 'house', '!', 'grips', 'weight', 'You', 'yeah', '1', 'on', 'KING', \"n't\", 'coconuts', 'through', 'maintain', 'Whoa', 'temperate', 'son', 'but', 'ridden', 'They', 'Arthur', \"'s\", ',', 'fly', 'servant', \"'\", 'search', 'our', 'interested', 'must', 'Are', 'Mercea', 'lord', 'line', 'creeper', 'where', 'clop', '[', 'using', 'It', 'empty', 'ARTHUR', 'is', 'suggesting', 'coconut', 'Yes', 'Court', 'here', 'have', 'climes', 'velocity', 'every', 'beat', 'get', 'wants', 'join', 'point', '#', 'me', 'length', 'No', 'a', 'court', 'martin', 'bird', '?', 'sun', 'Not', 'times', 'why', 'course', 'The', 'together', 'migrate', 'tell', 'two', 'question', \"'ve\", 'air-speed', 'that', 'just', 'goes', 'Britons', 'carrying', 'an', 'But', 'held', 'castle', 'zone', 'SOLDIER', 'swallow', 'non-migratory', 'this', 'Saxons', 'bring', 'We', 'mean', 'go', 'then', 'maybe', 'with', 'be', 'Pendragon', 'grip', 'plover', 'dorsal', '.', 'winter', 'your', ']', 'African', 'Patsy', 'it', 'ounce', 'horse', 'its', 'seek', 'Oh', 'right', 'Wait', 'will', 'matter', 'found', 'if', 'trusty', 'the', 'could', 'I', 'husk', 'simple', 'from', 'land', 'Well', 'anyway', 'guiding', 'forty-three', 'to', 'back', 'by', 'strand', 'at', 'warmer', '--', 'since', 'Halt', 'five', \"'re\", \"'m\", 'England', 'What', 'covered', 'tropical', 'or', 'other', 'strangers', 'feathers', 'of', 'does', 'halves'}\n"
     ]
    }
   ],
   "source": [
    "# import sent_tokenize and word_tokenize from nltk.tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)\n",
    "\n",
    "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(sentences[3])\n",
    "\n",
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(scene_one))\n",
    "\n",
    "# print the unique tokens result\n",
    "print(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More regex with re.search()\n",
    "\n",
    "In this exercise, you'll utilize re.search() and re.match() to find specific tokens. Both search and match expect regex patterns, similar to those you defined in an earlier exercise. You'll apply these regex library methods to the same Monty Python text from the nltk corpora.\n",
    "\n",
    "You have both scene_one and sentences available from the last exercise; now you can use them with re.search() and re.match() to extract and match more text.\n",
    "\n",
    "Instructions\n",
    " - Print the start and end indexes for the first occurence of the word \"coconuts\" in scene_one. To do this, first use re.search() to define match, and then use the .start() and .end() methods of match.\n",
    " - Write a regular expression called pattern1 to find anything in square brackets.\n",
    " - Use re.search() with the previous pattern to find the first text in square brackets in the scene.\n",
    " - Use re.match() to match the script notation in the fourth line (ARTHUR:) and print the result. The tokenized sentences of scene_one are available in your namespace as sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = ['SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!',\n",
    " '[clop clop clop] \\nSOLDIER #1: Halt!',\n",
    " 'Who goes there?',\n",
    " 'ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.',\n",
    " 'King of the Britons, defeator of the Saxons, sovereign of all England!',\n",
    " 'SOLDIER #1: Pull the other one!',\n",
    " 'ARTHUR: I am, ...  and this is my trusty servant Patsy.',\n",
    " 'We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.',\n",
    " 'I must speak with your lord and master.',\n",
    " 'SOLDIER #1: What?',\n",
    " 'Ridden on a horse?',\n",
    " 'ARTHUR: Yes!',\n",
    " \"SOLDIER #1: You're using coconuts!\",\n",
    " 'ARTHUR: What?',\n",
    " \"SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\",\n",
    " 'ARTHUR: So?',\n",
    " \"We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\",\n",
    " 'ARTHUR: We found them.',\n",
    " 'SOLDIER #1: Found them?',\n",
    " 'In Mercea?',\n",
    " \"The coconut's tropical!\",\n",
    " 'ARTHUR: What do you mean?',\n",
    " 'SOLDIER #1: Well, this is a temperate zone.',\n",
    " 'ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?',\n",
    " 'SOLDIER #1: Are you suggesting coconuts migrate?',\n",
    " 'ARTHUR: Not at all.',\n",
    " 'They could be carried.',\n",
    " 'SOLDIER #1: What?',\n",
    " 'A swallow carrying a coconut?',\n",
    " 'ARTHUR: It could grip it by the husk!',\n",
    " \"SOLDIER #1: It's not a question of where he grips it!\",\n",
    " \"It's a simple question of weight ratios!\",\n",
    " 'A five ounce bird could not carry a one pound coconut.',\n",
    " \"ARTHUR: Well, it doesn't matter.\",\n",
    " 'Will you go and tell your master that Arthur from the Court of Camelot is here.',\n",
    " 'SOLDIER #1: Listen.',\n",
    " 'In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?',\n",
    " 'ARTHUR: Please!',\n",
    " 'SOLDIER #1: Am I right?',\n",
    " \"ARTHUR: I'm not interested!\",\n",
    " 'SOLDIER #2: It could be carried by an African swallow!',\n",
    " 'SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.',\n",
    " \"That's my point.\",\n",
    " 'SOLDIER #2: Oh, yeah, I agree with that.',\n",
    " 'ARTHUR: Will you ask your master if he wants to join my court at Camelot?!',\n",
    " 'SOLDIER #1: But then of course a-- African swallows are non-migratory.',\n",
    " 'SOLDIER #2: Oh, yeah...',\n",
    " \"SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!\",\n",
    " 'Supposing two swallows carried it together?',\n",
    " \"SOLDIER #1: No, they'd have to have it on a line.\",\n",
    " 'SOLDIER #2: Well, simple!',\n",
    " \"They'd just use a strand of creeper!\",\n",
    " 'SOLDIER #1: What, held under the dorsal guiding feathers?',\n",
    " 'SOLDIER #2: Well, why not?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!',\n",
       " '[clop clop clop] \\nSOLDIER #1: Halt!',\n",
       " 'Who goes there?',\n",
       " 'ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.',\n",
       " 'King of the Britons, defeator of the Saxons, sovereign of all England!',\n",
       " 'SOLDIER #1: Pull the other one!',\n",
       " 'ARTHUR: I am, ...  and this is my trusty servant Patsy.',\n",
       " 'We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.',\n",
       " 'I must speak with your lord and master.',\n",
       " 'SOLDIER #1: What?',\n",
       " 'Ridden on a horse?',\n",
       " 'ARTHUR: Yes!',\n",
       " \"SOLDIER #1: You're using coconuts!\",\n",
       " 'ARTHUR: What?',\n",
       " \"SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\",\n",
       " 'ARTHUR: So?',\n",
       " \"We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\",\n",
       " 'ARTHUR: We found them.',\n",
       " 'SOLDIER #1: Found them?',\n",
       " 'In Mercea?',\n",
       " \"The coconut's tropical!\",\n",
       " 'ARTHUR: What do you mean?',\n",
       " 'SOLDIER #1: Well, this is a temperate zone.',\n",
       " 'ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?',\n",
       " 'SOLDIER #1: Are you suggesting coconuts migrate?',\n",
       " 'ARTHUR: Not at all.',\n",
       " 'They could be carried.',\n",
       " 'SOLDIER #1: What?',\n",
       " 'A swallow carrying a coconut?',\n",
       " 'ARTHUR: It could grip it by the husk!',\n",
       " \"SOLDIER #1: It's not a question of where he grips it!\",\n",
       " \"It's a simple question of weight ratios!\",\n",
       " 'A five ounce bird could not carry a one pound coconut.',\n",
       " \"ARTHUR: Well, it doesn't matter.\",\n",
       " 'Will you go and tell your master that Arthur from the Court of Camelot is here.',\n",
       " 'SOLDIER #1: Listen.',\n",
       " 'In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?',\n",
       " 'ARTHUR: Please!',\n",
       " 'SOLDIER #1: Am I right?',\n",
       " \"ARTHUR: I'm not interested!\",\n",
       " 'SOLDIER #2: It could be carried by an African swallow!',\n",
       " 'SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.',\n",
       " \"That's my point.\",\n",
       " 'SOLDIER #2: Oh, yeah, I agree with that.',\n",
       " 'ARTHUR: Will you ask your master if he wants to join my court at Camelot?!',\n",
       " 'SOLDIER #1: But then of course a-- African swallows are non-migratory.',\n",
       " 'SOLDIER #2: Oh, yeah...',\n",
       " \"SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!\",\n",
       " 'Supposing two swallows carried it together?',\n",
       " \"SOLDIER #1: No, they'd have to have it on a line.\",\n",
       " 'SOLDIER #2: Well, simple!',\n",
       " \"They'd just use a strand of creeper!\",\n",
       " 'SOLDIER #1: What, held under the dorsal guiding feathers?',\n",
       " 'SOLDIER #2: Well, why not?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More regex with re.search()\n",
    "\n",
    "In this exercise, you'll utilize re.search() and re.match() to find specific tokens. Both search and match expect regex patterns, similar to those you defined in an earlier exercise. You'll apply these regex library methods to the same Monty Python text from the nltk corpora.\n",
    "\n",
    "You have both scene_one and sentences available from the last exercise; now you can use them with re.search() and re.match() to extract and match more text.\n",
    "\n",
    "Instructions\n",
    " - Print the start and end indexes for the first occurence of the word \"coconuts\" in scene_one. To do this, first use re.search() to define match, and then use the .start() and .end() methods of match.\n",
    " - Write a regular expression called pattern1 to find anything in square brackets.\n",
    " - Use re.search() with the previous pattern to find the first text in square brackets in the scene.\n",
    " - Use re.match() to match the script notation in the fourth line (ARTHUR:) and print the result. The tokenized sentences of scene_one are available in your namespace as sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 588\n",
      "<_sre.SRE_Match object; span=(0, 7), match='ARTHUR:'>\n"
     ]
    }
   ],
   "source": [
    "# Search for the first occurrence of \"coconuts\" in scene_one: match\n",
    "match = re.search(\"coconuts\", scene_one)\n",
    "\n",
    "# Print the start and end indexes of match\n",
    "print(match.start(), match.end())\n",
    "\n",
    "# Write a regular expression to search for anything in square brackets: pattern1\n",
    "pattern1 = r\"\\[.*\\]\"\n",
    "\n",
    "# Use re.search to find the first text in square brackets\n",
    "re.search(pattern1, scene_one)\n",
    "\n",
    "# Find the script notation at the beginning of the fourth sentence and print it\n",
    "pattern2 = r\"[\\w\\s]+:\"\n",
    "print(re.match(pattern2, sentences[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint:\n",
    " - To create match, use re.search() with the arguments of interest - the word, followed by the scene. Once you've created match, you can use its  .start() and .end() methods inside a call to  print() to print the start and end indexes.\n",
    " - To create pattern1, use r\"\\[.*\\]\". You can then use it with scene_one in a call to re.search() to find the first text in square brackets.\n",
    " - To create pattern2, use r\"[\\w\\s]+:\". Then, you can use it with the fourth sentence (sentences[3]) in a call to re.match()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced tokenization with NLTK and regex - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Choosing a tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a tokenizer\n",
    "50xp\n",
    "Given the following string, which is the best tokenizer? If possible, we want to retain sentence punctuation as separate tokens, but have '#1' remain a single token.\n",
    "\n",
    "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n",
    "Possible Answers\n",
    "- r\"\\w+(\\?!)\"\n",
    "- r\"(\\w+|#\\d|\\?|!)\"\n",
    "- r\"(#\\d\\w+\\?!)\" (Correct)\n",
    "- r\"\\s+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r\"(#\\d\\w+\\?!)\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex with NLTK tokenization\n",
    "\n",
    "Twitter is a frequently used source for NLP text and tasks. In this exercise, you'll build a more complex tokenizer for tweets with hashtags and mentions using nltk and regex. The nltk.tokenize.TweetTokenizer class gives you some extra methods and attributes for parsing tweets.\n",
    "\n",
    "Here, you're given some example tweets to parse using both TweetTokenizer and regexp_tokenize from the nltk.tokenize module. These example tweets have been pre-loaded into the variable tweets. Feel free to explore it in the IPython Shell!\n",
    "\n",
    "Remember: | is like an \"or\" statement in regex and square brackets can be used to create groups.\n",
    "\n",
    "Instructions\n",
    " - Import the regexp_tokenize and TweetTokenizer from nltk.tokenize.\n",
    " - Define a regex pattern called pattern1 to match hashtags. A hashtag is something like #nlp. Then, call regexp_tokenize() with your new hashtag pattern on the first tweet in tweets.\n",
    " - Write a new pattern called pattern2 to match mentions and hashtags. A mention is something like @DataCamp. Then, call regexp_tokenize() with your new hashtag pattern on the last tweet in tweets. You can access the last element of a list using -1 as the index.\n",
    " - Create an instance of TweetTokenizer called tknzr and use it inside a list comprehension to tokenize each tweet into a new list called all_tokens. To do this, use the .tokenize() method of tknzr, with t as your iterator variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets=['This is the best #nlp exercise ive found online! #python',\n",
    " '#NLP is super fun! <3 #learning',\n",
    " 'Thanks @datacamp :) #nlp #python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the best #nlp exercise ive found online! #python',\n",
       " '#NLP is super fun! <3 #learning',\n",
       " 'Thanks @datacamp :) #nlp #python']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Define a regex pattern to find hashtags: pattern1\n",
    "pattern1 = r\"#\\w+\"\n",
    "\n",
    "# Use the pattern on the first tweet in the tweets list\n",
    "regexp_tokenize(tweets[0],pattern1)\n",
    "\n",
    "# Write a pattern that matches both mentions and hashtags\n",
    "pattern2 = r\"([#|@]\\w+)\"\n",
    "\n",
    "# Use the pattern on the last tweet in the tweets list\n",
    "regexp_tokenize(tweets[-1],pattern2)\n",
    "\n",
    "# Use the TweetTokenizer to tokenize all tweets into one list\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#nlp', '#python']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a regex pattern to find hashtags: pattern1\n",
    "pattern1 = r\"#\\w+\"\n",
    "\n",
    "# Use the pattern on the first tweet in the tweets list\n",
    "regexp_tokenize(tweets[0],pattern1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@datacamp', '#nlp', '#python']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a pattern that matches both mentions and hashtags\n",
    "pattern2 = r\"([#|@]\\w+)\"\n",
    "\n",
    "# Use the pattern on the last tweet in the tweets list\n",
    "regexp_tokenize(tweets[-1],pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the TweetTokenizer to tokenize all tweets into one list\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This',\n",
       "  'is',\n",
       "  'the',\n",
       "  'best',\n",
       "  '#nlp',\n",
       "  'exercise',\n",
       "  'ive',\n",
       "  'found',\n",
       "  'online',\n",
       "  '!',\n",
       "  '#python'],\n",
       " ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'],\n",
       " ['Thanks', '@datacamp', ':)', '#nlp', '#python']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint\n",
    "You can import x from y using the command from y import x.\n",
    "To create pattern1, use r\"#\\w+\". Then, pass it in as the second argument to regexp_tokenize(), where the first argument is tweets[0].\n",
    "To create pattern2, use r\"([#|@]\\w+)\". After this, you can use it with regexp_tokenize() as you did above.\n",
    "Use TweetTokenizer to create tknzr. Then, in the output expression of your list comprehension, use the .tokenize() method of tknzr. Be sure to use t as your iterator variable and tweets as your iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cooool',\n",
       " '#dummysmiley',\n",
       " ':',\n",
       " ':-)',\n",
       " ':-P',\n",
       " '<3',\n",
       " 'and',\n",
       " 'some',\n",
       " 'arrows',\n",
       " '<',\n",
       " '>',\n",
       " '->',\n",
       " '<--']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Other External Examples : \n",
    "tknzr = TweetTokenizer()\n",
    "s0 = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "tknzr.tokenize(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-ascii tokenization\n",
    "\n",
    "In this exercise, you'll practice advanced tokenization by tokenizing some non-ascii based text. You'll be using German with emoji!\n",
    "\n",
    "Here, you have access to a string called german_text. Explore it in the Shell and notice the German characters and emoji!\n",
    "\n",
    "The following modules have been pre-imported from nltk.tokenize: regexp_tokenize and word_tokenize.\n",
    "\n",
    "Unicode ranges for emoji are:\n",
    "\n",
    "('\\U0001F300'-'\\U0001F5FF'), ('\\U0001F600-\\U0001F64F'), ('\\U0001F680-\\U0001F6FF'), and ('\\u2600'-\\u26FF-\\u2700-\\u27BF').\n",
    "\n",
    "Instructions\n",
    " - Tokenize all the words in german_text.\n",
    " - Tokenize only the capital words in german_text.\n",
    " - First, write a pattern called capital_words to match only capital words.\n",
    " - Then, tokenize it using regexp_tokenize(). Make sure to check for the German Ü!\n",
    " - Tokenize only the emoji in german_text. To write the pattern, refer to the unicode ranges for emoji given in the assignment text, using | to separate them. You can then tokenize it using regexp_tokenize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_text='Wann gehen wir zum Pizza? 🍕 Und fährst du mit Über? 🚕'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint\n",
    "You can use word_tokenize() to tokenize the words in german_text.\n",
    "The pattern to match only capital words is r\"[A-ZÜ]\\w+\".\n",
    "    To write the pattern to match emoji, separate the unicode ranges for emoji shown in the assignment text using |. After writing the patterns, be sure to tokenize using regexp_tokenize() and then print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wann', 'Pizza', 'Und', 'Über']\n",
      "['🍕', '🚕']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the words in german_text\n",
    "word_tokenize(german_text)\n",
    "\n",
    "# Tokenize only capital words\n",
    "capital_words = r\"[A-ZÜ]\\w+\"\n",
    "print(regexp_tokenize(german_text, capital_words))\n",
    "\n",
    "# Tokenize only emoji\n",
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(german_text, emoji))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charting word length with NLTK - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charting practice\n",
    "\n",
    "Try using your new skills to find and chart the number of words per line in the script using matplotlib. The Holy Grail script is loaded for you, and you need to use regex to find the words per line.\n",
    "\n",
    "Using list comprehensions here will speed up your computations. For example: my_lines = [tokenize(l) for l in lines] will call a function tokenize on each line in the list lines. The new transformed list will be saved in the my_lines variable.\n",
    "\n",
    "You have access to the entire script in the variable holy_grail. Go for it!\n",
    "\n",
    "Instructions\n",
    "- Split the script into lines using the newline ('\\n') character.\n",
    "- Use re.sub() inside a list comprehension to replace the prompts such as ARTHUR: and SOLDIER #1. The pattern has been written for you.\n",
    "- Use a list comprehension to tokenize lines with regexp_tokenize(), keeping only words. Recall that the pattern for words is \"\\w+\".\n",
    "- Use a list comprehension to create a list of line lengths called line_num_words.\n",
    "- Use t_line as your iterator variable to iterate over tokenized_lines, and then len() function to compute line lengths.\n",
    "- Plot a histogram of line_num_words using plt.hist(). Don't forgot to use plt.show() as well to display the plot.\n",
    "- Take Hint (-30xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('grail.txt', 'r') as content_file:\n",
    "    holy_grail = content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\nSCENE 2: [thud] [clang] \\nCART-MASTER: Bring out your dead!  [clang] Bring out your dead!  [clang] Bring out your dead!  [clang] Bring out your dead!  [clang] Bring out your dead!  [cough cough...] [clang] [... cough cough] Bring out your dead!  [clang] Bring out your dead!  [clang] Bring out your dead!  Ninepence.  [clang] Bring out your dead!  [clang] Bring out your dead!  [clang] Bring out...  [rewr!] ... your dead!  [rewr!] [clang] Bring out your dead!\\nCUSTOMER: Here's one.\\nCART-MASTER: Ninepence.\\nDEAD PERSON: I'm not dead!\\nCART-MASTER: What?\\nCUSTOMER: Nothing.  Here's your ninepence.\\nDEAD PERSON: I'm not dead!\\nCART-MASTER: 'Ere.  He says he's not dead!\\nCUSTOMER: Yes he is.\\nDEAD PERSON: I'm not!\\nCART-MASTER: He isn't?\\nCUSTOMER: Well, he will be soon.  He's very ill.\\nDEAD PERSON: I'm getting better!  \\nCUSTOMER: No you're not.  You'll be stone dead in a moment.\\nCART-MASTER: Oh, I can't take him like that.  It's against regulations.\\nDEAD PERSON: I don't want to go on the cart!\\nCUSTOMER: Oh, don't be such a baby.\\nCART-MASTER: I can't take him.\\nDEAD PERSON: I feel fine!\\nCUSTOMER: Well, do us a favor.\\nCART-MASTER: I can't.\\nCUSTOMER: Well, can you hang around a couple of minutes?  He won't be long.\\nCART-MASTER: No, I've got to go to the Robinson's.  They've lost nine today.\\nCUSTOMER: Well, when's your next round?\\nCART-MASTER: Thursday.\\nDEAD PERSON: I think I'll go for a walk.\\nCUSTOMER: You're not fooling anyone you know.  Look, isn't there something you can do?\\nDEAD PERSON: [singing] I feel happy...  I feel happy.  [whop] \\nCUSTOMER: Ah, thanks very much.\\nCART-MASTER: Not at all.  See you on Thursday.\\nCUSTOMER: Right.  All right.  [howl] [clop clop clop] Who's that then?\\nCART-MASTER: I dunno.  Must be a king.\\nCUSTOMER: Why?\\nCART-MASTER: He hasn't got shit all over him.\\nSCENE 3: [thud] [King Arthur music] [thud thud thud] [King Arthur music stops] \\nARTHUR: Old woman!\\nDENNIS: Man!\\nARTHUR: Man.  Sorry.  What knight live in that castle over there?\\nDENNIS: I'm thirty-seven.\\nARTHUR: I-- what?\\nDENNIS: I'm thirty-seven.  I'm not old.\\nARTHUR: Well, I can't just call you 'Man'.\\nDENNIS: Well, you could say 'Dennis'.\\nARTHUR: Well, I didn't know you were called 'Dennis'.\\nDENNIS: Well, you didn't bother to find out, did you?\\nARTHUR: I did say 'sorry' about the 'old woman', but from the behind you looked--\\nDENNIS: What I object to is that you automatically treat me like an inferior!\\nARTHUR: Well, I am king!\\nDENNIS: Oh king, eh, very nice.  And how d'you get that, eh?  By exploiting the workers!  By 'anging on to outdated imperialist dogma which perpetuates the economic and social differences in our society.  If there's ever going to be any progress with the--\\nWOMAN: Dennis, there's some lovely filth down here.  Oh!  How d'you do?\\nARTHUR: How do you do, good lady.  I am Arthur, King of the Britons.  Who's castle is that?\\nWOMAN: King of the who?\\nARTHUR: The Britons.\\nWOMAN: Who are the Britons?\\nARTHUR: Well, we all are.  We are all Britons, and I am your king.\\nWOMAN: I didn't know we had a king.  I thought we were an autonomous collective.\\nDENNIS: You're fooling yourself.  We're living in a dictatorship.  A self-perpetuating autocracy in which the working classes--\\nWOMAN: Oh, there you go, bringing class into it again.\\nDENNIS: That's what it's all about.  If only people would hear of--\\nARTHUR: Please, please good people.  I am in haste.  Who lives in that castle?\\nWOMAN: No one live there.\\nARTHUR: Then who is your lord?\\nWOMAN: We don't have a lord.\\nARTHUR: What?\\nDENNIS: I told you.  We're an anarcho-syndicalist commune.  We take it in turns to act as a sort of executive officer for the week.\\nARTHUR: Yes.\\nDENNIS: But all the decision of that officer have to be ratified at a special bi-weekly meeting--\\nARTHUR: Yes, I see.\\nDENNIS: By a simple majority in the case of purely internal affairs,--\\nARTHUR: Be quiet!\\nDENNIS: But by a two-thirds majority in the case of more major--\\nARTHUR: Be quiet!  I order you to be quiet!\\nWOMAN: Order, eh?  Who does he think he is?  Heh.\\nARTHUR: I am your king!\\nWOMAN: Well, I didn't vote for you.\\nARTHUR: You don't vote for kings.\\nWOMAN: Well, how did you become king then?\\nARTHUR: The Lady of the Lake, ... [angels sing] ... her arm clad in the purest shimmering samite, held aloft Excalibur from the bosom of the water signifying by Divine Providence that I, Arthur, was to carry Excalibur. [singing stops] That is why I am your king!\\nDENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government.  Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.\\nARTHUR: Be quiet!\\nDENNIS: Well, but you can't expect to wield supreme executive power just 'cause some watery tart threw a sword at you!\\nARTHUR: Shut up!\\nDENNIS: I mean, if I went 'round saying I was an emperor just because some moistened bint had lobbed a scimitar at me, they'd put me away!\\nARTHUR: Shut up, will you.  Shut up!\\nDENNIS: Ah, now we see the violence inherent in the system.\\nARTHUR: Shut up!\\nDENNIS: Oh!  Come and see the violence inherent in the system!  Help, help!  I'm being repressed!\\nARTHUR: Bloody peasant!\\nDENNIS: Oh, what a give-away.  Did you hear that?  Did you hear that, eh?  That's what I'm on about.  Did you see him repressing me?  You saw it, didn't you\\nSCENE 4: [King Arthur music] [music stops] \\nBLACK KNIGHT: Aaagh!  [King Arthur music] [music stops] \\nBLACK KNIGHT: Aaagh!\\nGREEN KNIGHT: Ooh! [King Arthur music] [music stops] [stab] \\nBLACK KNIGHT: Aagh!\\nGREEN KNIGHT: Oh! [King Arthur music] Ooh! [music stops] \\nBLACK KNIGHT: Aaagh! [clang] \\nBLACK KNIGHT and GREEN KNIGHT: Agh!, oh!, etc.\\nGREEN KNIGHT: Aaaaaah!  Aaaaaaaaah! [woosh] [BLACK KNIGHT kills GREEN KNIGHT] [thud] [scrape] \\nBLACK KNIGHT: Umm! [clop clop clop] \\nARTHUR: You fight with the strength of many men, Sir Knight. [pause] I am Arthur, King of the Britons. [pause] I seek the finest and the bravest knights in the land to join me in my court at Camelot. [pause] You have proved yourself worthy.  Will you join me? [pause] You make me sad.  So be it.  Come, Patsy.\\nBLACK KNIGHT: None shall pass.\\nARTHUR: What?\\nBLACK KNIGHT: None shall pass.\\nARTHUR: I have no quarrel with you, good Sir Knight, but I must cross this bridge.\\nBLACK KNIGHT: Then you shall die.\\nARTHUR: I command you, as King of the Britons, to stand aside!\\nBLACK KNIGHT: I move for no man.\\nARTHUR: So be it!\\nARTHUR and BLACK KNIGHT: Aaah!, hiyaah!, etc. [ARTHUR chops the BLACK KNIGHT's left arm off] \\nARTHUR: Now stand aside, worthy adversary.\\nBLACK KNIGHT: 'Tis but a scratch.\\nARTHUR: A scratch?  Your arm's off!\\nBLACK KNIGHT: No, it isn't.\\nARTHUR: Well, what's that then?\\nBLACK KNIGHT: I've had worse.\\nARTHUR: You liar!\\nBLACK KNIGHT: Come on, you pansy! [clang] Huyah! [clang] Hiyaah! [clang] Aaaaaaaah! [ARTHUR chops the BLACK KNIGHT's right arm off] \\nARTHUR: Victory is mine! [kneeling] We thank Thee Lord, that in Thy mer--\\nBLACK KNIGHT: Hah! [clunk] Come on then.\\nARTHUR: What?\\nBLACK KNIGHT: Have at you! [kick] \\nARTHUR: Eh.  You are indeed brave, Sir Knight, but the fight is mine.\\nBLACK KNIGHT: Oh, had enough, eh?\\nARTHUR: Look, you stupid bastard.  You've got no arms left.\\nBLACK KNIGHT: Yes I have.\\nARTHUR: Look!\\nBLACK KNIGHT: Just a flesh wound. [kick] \\nARTHUR: Look, stop that.\\nBLACK KNIGHT: Chicken! [kick] Chickennn!\\nARTHUR: Look, I'll have your leg. [kick] Right! [whop] [ARTHUR chops the BLACK KNIGHT's right leg off] \\nBLACK KNIGHT: Right.  I'll do you for that!\\nARTHUR: You'll what?\\nBLACK KNIGHT: Come here!\\nARTHUR: What are you going to do, bleed on me?\\nBLACK KNIGHT: I'm invincible!\\nARTHUR: You're a looney.\\nBLACK KNIGHT: The Black Knight always triumphs!  Have at you!  Come on then. [whop] [ARTHUR chops the BLACK KNIGHT's last leg off] \\nBLACK KNIGHT: Ooh.  All right, we'll call it a draw.\\nARTHUR: Come, Patsy.\\nBLACK KNIGHT: Oh.  Oh, I see.  Running away, eh?  You yellow bastards!  Come back here and take what's coming to you.  I'll bite your legs off\\nSCENE 5:\\nMONKS: [chanting] Pie Iesu domine, dona eis requiem. [bonk] Pie Iesu domine, ... [bonk] ... dona eis requiem. [bonk] Pie Iesu domine, ... [bonk] ... dona eis requiem.\\nCROWD: A witch!  A witch! [bonk] A witch!  A witch!\\nMONKS: [chanting] Pie Iesu domine...\\nCROWD: A witch!  A witch!  A witch!  A witch!  We've found a witch!  A witch!  A witch!  A witch!  A witch!  We've got a witch!  A witch!  A witch!  Burn her!  Burn her!  Burn her!  We've found a witch!  We've found a witch!  A witch!  A witch!  A witch!\\nVILLAGER #1: We have found a witch.  May we burn her?\\nCROWD: Burn her!  Burn!  Burn her!  Burn her!\\nBEDEVERE: How do you know she is a witch?\\nVILLAGER #2: She looks like one.\\nCROWD: Right!  Yeah!  Yeah!\\nBEDEVERE: Bring her forward.\\nWITCH: I'm not a witch.  I'm not a witch.\\nBEDEVERE: Uh, but you are dressed as one.\\nWITCH: They dressed me up like this.\\nCROWD: Augh, we didn't!  We didn't...\\nWITCH: And this isn't my nose.  It's a false one.\\nBEDEVERE: Well?\\nVILLAGER #1: Well, we did do the nose.\\nBEDEVERE: The nose?\\nVILLAGER #1: And the hat, but she is a witch!\\nVILLAGER #2: Yeah!\\nCROWD: We burn her!  Right!  Yeaaah!  Yeaah!\\nBEDEVERE: Did you dress her up like this?\\nVILLAGER #1: No!\\nVILLAGER #2 and 3: No.  No.\\nVILLAGER #2: No.\\nVILLAGER #1: No.\\nVILLAGERS #2 and #3: No.\\nVILLAGER #1: Yes.\\nVILLAGER #2: Yes.\\nVILLAGER #1: Yes.  Yeah, a bit.\\nVILLAGER #3: A bit.\\nVILLAGERS #1 and #2: A bit.\\nVILLAGER #3: A bit.\\nVILLAGER #1: She has got a wart.\\nRANDOM: [cough] \\nBEDEVERE: What makes you think she is a witch?\\nVILLAGER #3: Well, she turned me into a newt.\\nBEDEVERE: A newt?\\nVILLAGER #3: I got better.\\nVILLAGER #2: Burn her anyway!\\nVILLAGER #1: Burn!\\nCROWD: Burn her!  Burn!  Burn her! ...\\nBEDEVERE: Quiet!  Quiet!  Quiet!  Quiet!  There are ways of telling whether she is a witch.\\nVILLAGER #1: Are there?\\nVILLAGER #2: Ah?\\nVILLAGER #1: What are they?\\nCROWD: Tell us!  Tell us! ...\\nBEDEVERE: Tell me, what do you do with witches?\\nVILLAGER #2: Burn!\\nVILLAGER #1: Burn!\\nCROWD: Burn!  Burn them up!  Burn! ...\\nBEDEVERE: And what do you burn apart from witches?\\nVILLAGER #1: More witches!\\nVILLAGER #3: Shh!\\nVILLAGER #2: Wood!\\nBEDEVERE: So, why do witches burn? [pause] \\nVILLAGER #3: B--...  'cause they're made of...  wood?\\nBEDEVERE: Good!  Heh heh.\\nCROWD: Oh yeah.  Oh.\\nBEDEVERE: So, how do we tell whether she is made of wood?\\nVILLAGER #1: Build a bridge out of her.\\nBEDEVERE: Ah, but can you not also make bridges out of stone?\\nVILLAGER #1: Oh, yeah.\\nRANDOM: Oh, yeah.  True.  Uhh...\\nBEDEVERE: Does wood sink in water?\\nVILLAGER #1: No.  No.\\nVILLAGER #2: No, it floats!  It floats!\\nVILLAGER #1: Throw her into the pond!\\nCROWD: The pond!  Throw her into the pond!\\nBEDEVERE: What also floats in water?\\nVILLAGER #1: Bread!\\nVILLAGER #2: Apples!\\nVILLAGER #3: Uh, very small rocks!\\nVILLAGER #1: Cider!\\nVILLAGER #2: Uh, gra-- gravy!\\nVILLAGER #1: Cherries!\\nVILLAGER #2: Mud!\\nVILLAGER #3: Churches!  Churches!\\nVILLAGER #2: Lead!  Lead!\\nARTHUR: A duck!\\nCROWD: Oooh.\\nBEDEVERE: Exactly.  So, logically...\\nVILLAGER #1: If...  she...  weighs...  the same as a duck, ...  she's made of wood.\\nBEDEVERE: And therefore?\\nVILLAGER #2: A witch!\\nVILLAGER #1: A witch!\\nCROWD: A witch!  A witch! ...\\nVILLAGER #4: Here is a duck.  Use this duck. [quack quack quack] \\nBEDEVERE: We shall use my largest scales.\\nCROWD: Ohh!  Ohh!  Burn the witch!  Burn the witch!  Burn her!  Burn her!  Burn her!  Burn her!  Burn her!  Burn her!  Burn her!  Ahh!  Ahh...\\nBEDEVERE: Right.  Remove the supports! [whop] [clunk] [creak] \\nCROWD: A witch!  A witch!  A witch!\\nWITCH: It's a fair cop.\\nVILLAGER #3: Burn her!\\nCROWD: Burn her!  Burn her!  Burn her!  Burn!  Burn! ...\\nBEDEVERE: Who are you who are so wise in the ways of science?\\nARTHUR: I am Arthur, King of the Britons.\\nBEDEVERE: My liege!\\nARTHUR: Good Sir Knight, will you come with me to Camelot, and join us at the Round Table?\\nBEDEVERE: My liege!  I would be honored.\\nARTHUR: What is your name?\\nBEDEVERE: Bedevere, my liege.\\nARTHUR: Then I dub you Sir Bedevere, Knight of the Round Table\\nNARRATOR: The wise Sir Bedevere was the first to join King Arthur's knights, but other illustrious names were soon to follow: Sir Lancelot the Brave; Sir Gallahad the Pure; and Sir Robin the-not-quite-so-brave-as-Sir-Lancelot, who had nearly fought the Dragon of Angnor, who had nearly stood up to the vicious Chicken of Bristol, and who had personally wet himself at the Battle of Badon Hill; and the aptly named Sir Not-appearing-in-this-film.  Together they formed a band whose names and deeds were to be retold throughout the centuries: the Knights of the Round Table\\nSCENE 6: [clop clop clop] \\nSIR BEDEVERE: And that, my liege, is how we know the earth to be banana-shaped.\\nARTHUR: This new learning amazes me, Sir Bedevere.  Explain again how sheep's bladders may be employed to prevent earthquakes.\\nBEDEVERE: Oh, certainly, sir.\\nSIR LAUNCELOT: Look, my liege! [trumpets] \\nARTHUR: Camelot!\\nSIR GALAHAD: Camelot!\\nLAUNCELOT: Camelot!\\nPATSY: It's only a model.\\nARTHUR: Shh!  Knights, I bid you welcome to your new home.  Let us ride... to...  Camelot! [in medieval hall] \\nKNIGHTS: [singing] We're knights of the round table.  We dance when e'er we're able.  We do routines and chorus scenes With footwork impeccable.  We dine well here in Camelot.  We eat ham and jam and spam a lot [dancing] We're knights of the Round Table. Our shows are formidable, But many times we're given rhymes That are quite unsingable. We're opera mad in Camelot. We sing from the diaphragm a lot [in dungeon] \\nPRISONER: [clap clap clap clap] [in medieval hall] \\nKNIGHTS: [tap-dancing] In war we're tough and able, Quite indefatigable.  Between our quests we sequin vests and impersonate Clark Gable.  It's a busy life in Camelot.\\nMAN: I have to push the pram a lot [outdoors] \\nARTHUR: Well, on second thought, let's not go to Camelot.  It is a silly place.\\nKNIGHTS: Right.  Right\\nSCENE 7: [clop clop clop] [boom boom] [angels sing] \\nGOD: Arthur!  Arthur, King of the Britons!  Oh, don't grovel! [singing stops] One thing I can't stand, it's people groveling.\\nARTHUR: Sorry. [boom] \\nGOD: And don't apologise.  Every time I try to talk to someone it's 'sorry this' and 'forgive me that' and 'I'm not worthy'. [boom] What are you doing now?!\\nARTHUR: I'm averting my eyes, O Lord.\\nGOD: Well, don't.  It's like those miserable Psalms-- they're so depressing. Now knock it off!\\nARTHUR: Yes, Lord.\\nGOD: Right!  Arthur, King of the Britons, your Knights of the Round Table shall have a task to make them an example in these dark times.\\nARTHUR: Good idea, O Lord!\\nGOD: 'Course it's a good idea!  Behold! [angels sing] Arthur, this is the Holy Grail.  Look well, Arthur, for it is your sacred task to seek this grail.  That is your purpose, Arthur...  the quest for the Holy Grail. [boom] [singing stops] \\nLAUNCELOT: A blessing!  A blessing from the Lord!\\nGALAHAD: God be praised\\nSCENE 8: [King Arthur music] [clop clop clop] \\nARTHUR: Halt! [horn] Hallo! [pause] Hallo!\\nFRENCH GUARD: Allo!  Who is eet?\\nARTHUR: It is King Arthur, and these are my Knights of the Round Table.  Who's castle is this?\\nFRENCH GUARD: This is the castle of my master Guy de Loimbard.\\nARTHUR: Go and tell your master that we have been charged by God with a sacred quest.  If he will give us food and shelter for the night he can join us in our quest for the Holy Grail.\\nFRENCH GUARD: Well, I'll ask him, but I don't think he'll be very keen.  Uh, he's already got one, you see?\\nARTHUR: What?\\nGALAHAD: He says they've already got one!\\nARTHUR: Are you sure he's got one?\\nFRENCH GUARD: Oh, yes, it's very nice-a.  (I told him we already got one.)\\nARTHUR: Well, u-- um, can we come up and have a look?\\nFRENCH GUARD: Of course not!  You are English types-a!\\nARTHUR: Well, what are you then?\\nFRENCH GUARD: I'm French!  Why do think I have this outrageous accent, you silly king-a?!\\nGALAHAD: What are you doing in England?\\nFRENCH GUARD: Mind your own business!\\nARTHUR: If you will not show us the Grail, we shall take your castle by force!\\nFRENCH GUARD: You don't frighten us, English pig-dogs!  Go and boil your bottom, sons of a silly person.  I blow my nose at you, so-called Arthur King, you and all your silly English k-nnnnniggets.  Thpppppt!  Thppt! Thppt!\\nGALAHAD: What a strange person.\\nARTHUR: Now look here, my good man--\\nFRENCH GUARD: I don't wanna talk to you no more, you empty headed animal food trough wiper!  I fart in your general direction!  You mother was a hamster and your father smelt of elderberries!\\nGALAHAD: Is there someone else up there we could talk to?\\nFRENCH GUARD: No, now go away or I shall taunt you a second time-a! [sniff] \\nARTHUR: Now, this is your last chance.  I've been more than reasonable.\\nFRENCH GUARD: (Fetchez la vache.)\\nOTHER FRENCH GUARD: Quoi?\\nFRENCH GUARD: (Fetchez la vache!) [mooo] \\nARTHUR: If you do not agree to my commands, then I shall-- [twong] [mooooooo] Jesus Christ!\\nKNIGHTS: Christ! [thud] Ah!  Ohh!\\nARTHUR: Right!  Charge!\\nKNIGHTS: Charge! [mayhem] \\nFRENCH GUARD: Hey, this one is for your mother!  There you go. [mayhem] \\nFRENCH GUARD: And this one's for your dad!\\nARTHUR: Run away!\\nKNIGHTS: Run away!\\nFRENCH GUARD: Thppppt!\\nFRENCH GUARDS: [taunting] \\nLAUNCELOT: Fiends!  I'll tear them apart!\\nARTHUR: No, no.  No, no.\\nBEDEVERE: Sir!  I have a plan, sir. [later] [wind] [saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw] [clunk] [bang] [rewr!] [squeak squeak squeak squeak squeak squeak squeak squeak squeak squeak] [rrrr rrrr rrrr] [drilllll] [sawwwww] [clunk] [crash] [clang] [squeak squeak squeak squeak squeak...] [creak] \\nFRENCH GUARDS: [whispering] C'est un lapin, lapin de bois.  Quoi?  Un cadeau.  What?  A present.  Oh, un cadeau.  Oui, oui.  Hurry.  What?  Let's go.  Oh. On y va.  Bon magne.  Over here... [squeak squeak squeak squeak squeak...] [clllank] \\nARTHUR: What happens now?\\nBEDEVERE: Well, now, uh, Launcelot, Galahad, and I, uh, wait until nightfall, and then leap out of the rabbit, taking the French, uh, by surprise.  Not only by surprise, but totally unarmed!\\nARTHUR: Who leaps out?\\nBEDEVERE: U-- u-- uh, Launcelot, Galahad, and I.  Uh, leap out of the rabbit, uh, and uh...\\nARTHUR: Ohh.\\nBEDEVERE: Oh.  Um, l-- look, i-- i-- if we built this large wooden badger-- [clank] [twong] \\nARTHUR: Run away!\\nKNIGHTS: Run away!  Run away!  Run away!  Run away!  Run away!  Run away!  Run away! [CRASH] \\nFRENCH GUARDS: Oh, haw haw haw haw!  Haw!  Haw haw heh..\\nSCENE 9: [clack] \\nVOICE: Picture for Schools, take eight.\\nDIRECTOR: Action!\\nHISTORIAN: Defeat at the castle seems to have utterly disheartened King Arthur.  The ferocity of the French taunting took him completely by surprise, and Arthur became convinced that a new strategy was required if the quest for the Holy Grail were to be brought to a successful conclusion.  Arthur, having consulted his closest knights, decided that they should separate, and search for the Grail individually. [clop clop clop] Now, this is what they did: Launcelot--\\nKNIGHT: Aaaah! [slash] [KNIGHT kills HISTORIAN] \\nHISTORIAN'S WIFE: Frank\\nSCENE 10: [trumpets] \\nNARRATOR: The Tale of Sir Robin.  So each of the knights went their separate ways.  Sir Robin rode north, through the dark forest of Ewing, accompanied by his favorite minstrels.\\nMINSTREL: [singing] Bravely bold Sir Robin, rode forth from Camelot.  He was not afraid to die, O brave Sir Robin.  He was not at all afraid to be killed in nasty ways.  Brave, brave, brave, brave Sir Robin!  He was not in the least bit scared to be mashed into a pulp, Or to have his eyes gouged out, and his elbows broken.  To have his kneecaps split, and his body burned away, And his limbs all hacked and mangled, brave Sir Robin!\\nHis head smashed in and his heart cut out, And his liver removed and his bowels unplugged, And his nostrils raped and his bottom burned off, And his pen--\\nSIR ROBIN: That's-- that's, uh-- that's enough music for now, lads.  Heh.  Looks like there's dirty work afoot.\\nDENNIS: Anarcho-syndicalism is a way of preserving freedom.\\nWOMAN: Oh, Dennis, forget about freedom.  We haven't got enough mud.\\nALL HEADS: Halt!  Who art thou?\\nMINSTREL: [singing] He is brave Sir Robin, brave Sir Robin, who--\\nROBIN: Shut up!  Um, n-- n-- n-- nobody really, I'm j-- j-- j-- ju-- just um, just passing through.\\nALL HEADS: What do you want?\\nMINSTREL: [singing] To fight and--\\nROBIN: Shut up!  Um, oo, a-- nothing, nothing really.  I, uh, j-- j-- just--just to um, just to p-- pass through, good Sir Knight.\\nALL HEADS: I'm afraid not!\\nROBIN: Ah.  W-- well, actually I-- I am a Knight of the Round Table.\\nALL HEADS: You're a Knight of the Round Table?\\nROBIN: I am.\\nLEFT HEAD: In that case I shall have to kill you.\\nMIDDLE HEAD: Shall I?\\nRIGHT HEAD: Oh, I don't think so.\\nMIDDLE HEAD: Well, what do I think?\\nLEFT HEAD: I think kill him.\\nRIGHT HEAD: Oh, let's be nice to him.\\nLEFT HEAD: Oh shut up.\\nROBIN: Perhaps I could--\\nLEFT HEAD: And you.  Oh, quick!  Get the sword out.  I want to cut his headoff!\\nRIGHT HEAD: Oh, cut your own head off!\\nMIDDLE HEAD: Yes, do us all a favor!\\nLEFT HEAD: What?\\nRIGHT HEAD: Yapping on all the time.\\nMIDDLE HEAD: You're lucky.  You're not next to him.\\nLEFT HEAD: What do you mean?\\nMIDDLE HEAD: You snore!\\nLEFT HEAD: Oh, I don't.  Anyway, you've got bad breath.\\nMIDDLE HEAD: Well it's only because you don't brush my teeth.\\nRIGHT HEAD: Oh stop bitching and let's go have tea.\\nLEFT HEAD: Oh, all right.  All right.  All right.  We'll kill him first and then have tea and biscuits.\\nMIDDLE HEAD: Yes.\\nRIGHT HEAD: Oh, not biscuits.\\nLEFT HEAD: All right.  All right, not biscuits, but let's kill him anyway.\\nALL HEADS: Right!\\nMIDDLE HEAD: He buggered off.\\nRIGHT HEAD: So he has.  He's scarper\\nMINSTREL: [singing] Brave Sir Robin ran away.\\nROBIN: No!\\nMINSTREL: [singing] Bravely ran away away.\\nROBIN: I didn't!\\nMINSTREL: [singing] When danger reared its ugly head, he bravely turned his tail and fled.\\nROBIN: No!\\nMINSTREL: [singing] Yes, brave Sir Robin turned about\\nROBIN: I didn't!\\nMINSTREL: [singing] And gallantly he chickened out, bravely taking to his feet.\\nROBIN: I never did!\\nMINSTREL: [singing] He beat a very brave retreat.\\nROBIN: All lies!\\nMINSTREL: [singing] Bravest of the brave, Sir Robin.\\nROBIN: I never\\nCARTOON MONKS: [chanting] Pie Iesu domine, dona eis requiem.\\nCARTOON CHARACTER: Heh heh heeh ooh... [twang] \\nCARTOON MONKS: [chanting] Pie Iesu domine, ...\\nCARTOON CHARACTERS: Wayy! [splash] Ho ho.  Woa, wayy! [twang] [splash] Heh heh heh heh ho!  Heh heh heh!\\nCARTOON MONKS: [chanting] ... dona eis requiem.\\nCARTOON CHARACTER: Wayy! [twang] Wayy! [twang] \\nVOICE: [whispering] Forgive me for asking.\\nCARTOON CHARACTER: Oh!  Oooo\\nSCENE 11: [trumpets] \\nNARRATOR: The Tale of Sir Galahad. [boom] [wind] [howl] [howl] [boom] [angels singing] [howl] [boom] [howl] [boom] [pound pound pound] \\nGALAHAD: Open the door!  Open the door! [pound pound pound] In the name of King Arthur, open the door! [squeak] [thump] [squeak] [boom] \\nGIRLS: Hello!\\nZOOT: Welcome gentle Sir Knight.  Welcome to the Castle Anthrax.\\nGALAHAD: The Castle Anthrax?\\nZOOT: Yes.  Oh, it's not a very good name is it?  Oh, but we are nice and we will attend to your every, every need!\\nGALAHAD: You are the keepers of the Holy Grail?\\nZOOT: The what?\\nGALAHAD: The Grail.  It is here.\\nZOOT: Oh, but you are tired, and you must rest awhile.  Midget!  Crapper!\\nMIDGET and CRAPPER: Yes, O Zoot?\\nZOOT: Prepare a bed for our guest.\\nMIDGET and CRAPPER: Oh thank you!  Thank you!  Thank you!  Thank you!  Thank you!  Thank you! ...\\nZOOT: Away, away varletesses.  The beds here are warm and soft, and very, very big.\\nGALAHAD: Well, look, I-- I-- uh--\\nZOOT: What is your name, handsome knight?\\nGALAHAD: Sir Galahad...  the Chaste.\\nZOOT: Mine is Zoot.  Just Zoot.  Oh, but come.\\nGALAHAD: Look, please!  In God's name, show me the Grail!\\nZOOT: Oh, you have suffered much.  You are delirious.\\nGALAHAD: No, look.  I have seen it!  It is here, in this--\\nZOOT: Sir Galahad!  You would not be so ungallant as to refuse our hospitality.\\nGALAHAD: Well, I-- I-- uh--\\nZOOT: Oh, I am afraid our life must seem very dull and quiet compared to yours.  We are but eight score young blondes and brunettes, all between sixteen and nineteen-and-a-half, cut off in this castle with no one to protect us.  Oooh.  It is a lonely life: bathing, dressing, undressing, making exciting underwear.  We are just not used to handsome knights.  Nay.  Nay.  Come.  Come.  You may lie here.  Oh, but you are wounded!\\nGALAHAD: No, no-- it's-- it's nothing.\\nZOOT: Oh, you must see the doctors immediately!  No, no, please!  Lie down. [clap clap] \\nPIGLET: Well, what seems to be the trouble?\\nGALAHAD: They're doctors?!\\nZOOT: Uh, they have a basic medical training, yes.\\nGALAHAD: B-- but--\\nZOOT: Oh, come, come.  You must try to rest.  Doctor Piglet!  Doctor Winston!  Practice your art.\\nWINSTON: Try to relax.\\nGALAHAD: Are you sure that's absolutely necessary?\\nPIGLET: We must examine you.\\nGALAHAD: There's nothing wrong with that!\\nPIGLET: Please.  We are doctors.\\nGALAHAD: Look!  This cannot be.  I am sworn to chastity.\\nPIGLET: Back to your bed!  At once!\\nGALAHAD: Torment me no longer.  I have seen the Grail!\\nPIGLET: There's no grail here.\\nGALAHAD: I have seen it!  I have seen it! [clank] I have seen--\\nGIRLS: Hello.\\nGALAHAD: Oh.\\nGIRLS: Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.\\nGALAHAD: Zoot!\\nDINGO: No, I am Zoot's identical twin sister, Dingo.\\nGALAHAD: Oh, well, excuse me, I--\\nDINGO: Where are you going?\\nGALAHAD: I seek the Grail!  I have seen it, here in this castle!\\nDINGO: Oh no.  Oh, no!  Bad, bad Zoot!\\nGALAHAD: Well, what is it?\\nDINGO: Oh, wicked, bad, naughty Zoot!  She has been setting alight to our beacon, which, I have just remembered, is grail-shaped.  It's not the first time we've had this problem.\\nGALAHAD: It's not the real Grail?\\nDINGO: Oh, wicked, bad, naughty, evil Zoot!  She is a bad person and must pay the penalty.  Do you think this scene should have been cut?  We were so worried when the boys were writing it, but now, we're glad.  It's better than some of the previous scenes, I think.\\nLEFT HEAD: At least ours was better visually.\\nDENNIS: Well, at least ours was committed.  It wasn't just a string of pussy jokes.\\nOLD MAN: Get on with it.\\nTIM THE ENCHANTER: Yes, get on with it!\\nARMY OF KNIGHTS: Yes, get on with it!\\nDINGO: Oh, I am enjoying this scene.\\nGOD: Get on with it!\\nDINGO: [sigh] Oh, wicked, wicked Zoot.  Oh, she is a naughty person, and she must pay the penalty.  And here in Castle Anthrax, we have but one punishment for setting alight the grail-shaped beacon.  You must tie her down on a bed and spank her.\\nGIRLS: A spanking!  A spanking!\\nDINGO: You must spank her well.  And after you have spanked her, you may deal with her as you like.  And then, spank me.\\nAMAZING: And spank me.\\nSTUNNER: And me.\\nLOVELY: And me.\\nDINGO: Yes, yes, you must give us all a good spanking!\\nGIRLS: A spanking!  A spanking!  There is going to be a spanking tonight!\\nDINGO: And after the spanking, the oral sex.\\nGIRLS: The oral sex!  The oral sex!\\nGALAHAD: Well, I could stay a bit longer.\\nLAUNCELOT: Sir Galahad!\\nGALAHAD: Oh, hello.\\nLAUNCELOT: Quick!\\nGALAHAD: What?\\nLAUNCELOT: Quick!\\nGALAHAD: Why?\\nLAUNCELOT: You are in great peril!\\nDINGO: No he isn't.\\nLAUNCELOT: Silence, foul temptress!\\nGALAHAD: You know, she's got a point.\\nLAUNCELOT: Come on!  We will cover your escape!\\nGALAHAD: Look, I'm fine!\\nLAUNCELOT: Come on!\\nGIRLS: Sir Galahad!\\nGALAHAD: No.  Look, I can tackle this lot single-handed!\\nDINGO: Yes!  Let him tackle us single-handed!\\nGIRLS: Yes!  Let him tackle us single-handed!\\nLAUNCELOT: No, Sir Galahad.  Come on!\\nGALAHAD: No!  Really!  Honestly, I can cope.  I can handle this lot easily.\\nDINGO: Oh, yes.  Let him handle us easily.\\nGIRLS: Yes.  Let him handle us easily.\\nLAUNCELOT: No.  Quick!  Quick!\\nGALAHAD: Please!  I can defeat them!  There's only a hundred-and-fifty of them!\\nDINGO: Yes, yes!  He will beat us easily!  We haven't a chance.\\nGIRLS: We haven't a chance.  He will beat us easily... [boom] \\nDINGO: Oh, shit.\\nLAUNCELOT: We were in the nick of time.  You were in great peril.\\nGALAHAD: I don't think I was.\\nLAUNCELOT: Yes you were.  You were in terrible peril.\\nGALAHAD: Look, let me go back in there and face the peril.\\nLAUNCELOT: No, it's too perilous.\\nGALAHAD: Look, it's my duty as a knight to sample as much peril as I can.\\nLAUNCELOT: No, we've got to find the Holy Grail.  Come on!\\nGALAHAD: Oh, let me have just a little bit of peril?\\nLAUNCELOT: No.  It's unhealthy.\\nGALAHAD: I bet you're gay.\\nLAUNCELOT: No I'm not\\nNARRATOR: Sir Launcelot had saved Sir Galahad from almost certain temptation, but they were still no nearer the Grail.  Meanwhile, King Arthur and Sir Bedevere, not more than a swallow's flight away, had discovered something.  Oh, that's an unladen swallow's flight, obviously.  I mean, they were more than two laden swallows' flights away-- four, really, if they had a coconut on a line between them.  I mean, if the birds were walking and dragging--\\nCROWD: Get on with it!\\nNARRATOR: Oh, anyway.  On to scene twenty-four, which is a smashing scene with some lovely acting, in which Arthur discovers a vital clue, and in which there aren't any swallows, although I think you can hear a starling-- oooh\\nSCENE 12:\\nOLD MAN: Heh, hee ha ha hee hee!  Hee hee hee ha ha ha...\\nARTHUR: And this enchanter of whom you speak, he has seen the Grail?\\nOLD MAN: ... Ha ha ha ha!  Heh, hee ha ha hee!  Ha hee ha!  Ha ha ha ha...\\nARTHUR: Where does he live?\\nOLD MAN: ... Heh heh heh heh...\\nARTHUR: Old man, where does he live?\\nOLD MAN: ... Hee ha ha ha.  He knows of a cave, a cave which no man has entered.\\nARTHUR: And the Grail.  The Grail is there?\\nOLD MAN: There is much danger, for beyond the cave lies the Gorge of Eternal Peril, which no man has ever crossed.\\nARTHUR: But the Grail!  Where is the Grail?!\\nOLD MAN: Seek you the Bridge of Death.\\nARTHUR: The Bridge of Death, which leads to the Grail?\\nOLD MAN: Heh, hee hee hee hee!  Ha ha ha ha ha!  Hee ha ha..\\nSCENE 13: [spooky music] [music stops] \\nHEAD KNIGHT OF NI: Ni!\\nKNIGHTS OF NI: Ni!  Ni!  Ni!  Ni!  Ni!\\nARTHUR: Who are you?\\nHEAD KNIGHT: We are the Knights Who Say...  'Ni'!\\nRANDOM: Ni!\\nARTHUR: No!  Not the Knights Who Say 'Ni'!\\nHEAD KNIGHT: The same!\\nBEDEVERE: Who are they?\\nHEAD KNIGHT: We are the keepers of the sacred words: Ni, Peng, and Neee-wom!\\nRANDOM: Neee-wom!\\nARTHUR: Those who hear them seldom live to tell the tale!\\nHEAD KNIGHT: The Knights Who Say 'Ni' demand a sacrifice!\\nARTHUR: Knights of Ni, we are but simple travellers who seek the enchanter who lives beyond these woods.\\nHEAD KNIGHT: Ni!\\nKNIGHTS OF NI: Ni!  Ni!  Ni!  Ni!  Ni! ...\\nARTHUR: Ow!  Ow!  Ow!  Agh!\\nHEAD KNIGHT: We shall say 'ni' again to you if you do not appease us.\\nARTHUR: Well, what is it you want?\\nHEAD KNIGHT: We want...  a shrubbery! [dramatic chord] \\nARTHUR: A what?\\nKNIGHTS OF NI: Ni!  Ni!  Ni!  Ni!\\nARTHUR and PARTY: Ow!  Oh!\\nARTHUR: Please, please!  No more!  We will find you a shrubbery.\\nHEAD KNIGHT: You must return here with a shrubbery or else you will never pass through this wood alive!\\nARTHUR: O Knights of Ni, you are just and fair, and we will return with a shrubbery.\\nHEAD KNIGHT: One that looks nice.\\nARTHUR: Of course.\\nHEAD KNIGHT: And not too expensive.\\nARTHUR: Yes.\\nHEAD KNIGHT: Now...  go [trumpets] \\nCARTOON CHARACTER: Hmm hmm-- [boom] Oh!  Great scott!  Hm.  Hmm. [boom] Hm!  Hmm.  [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] [mumble mumble mumble] [boom] Ohh! [crash] [mumble mumble mumble] [boom] \\nSUN: Ay, up!  Thsss. [boom] Ayy, up! [boom] Thsss. [boom] Ayy, up!\\nCARTOON CHARACTER: Stop that!  Stop that! [boom] \\nSUN: Ay, up!\\nCARTOON CHARACTER: Stop that! [boom] Look on!  Clear off!  Go on!  Go away!  Go away!  Go away!  And you!  Clear off!  [sniff] \\nSUN: [mumble mumble mumble] [bells] \\nCARTOON CHARACTER: Hah.  Bloody weather\\nSCENE 14:\\nNARRATOR: The Tale of Sir Launcelot.\\nFATHER: One day, lad, all this will be yours!\\nPRINCE HERBERT: What, the curtains?\\nFATHER: No.  Not the curtains, lad.  All that you can see, stretched out over the hills and valleys of this land!  This'll be your kingdom, lad.\\nHERBERT: But Mother--\\nFATHER: Father, lad.  Father.\\nHERBERT: B-- b-- but Father, I don't want any of that.\\nFATHER: Listen, lad.  I built this kingdom up from nothing.  When I started here, all there was was swamp.  Other kings said I was daft to build a castle on a swamp, but I built it all the same, just to show 'em.  It sank into the swamp.  So, I built a second one.  That sank into the swamp.  So I built a third one.  That burned down, fell over, then sank into the swamp.  But the fourth one...  stayed up!  And that's what you're gonna get, lad: the strongest castle in these islands.\\nHERBERT: But I don't want any of that.  I'd rather--\\nFATHER: Rather what?!\\nHERBERT: I'd rather... [music] ... just...  sing!\\nFATHER: Stop that!  Stop that!  You're not going into a song while I'm here.  Now listen, lad.  In twenty minutes you're getting married to a girl whose father owns the biggest tracts of open land in Britain.\\nHERBERT: B-- but I don't want land.\\nFATHER: Listen, Alice,--\\nHERBERT: Herbert.\\nFATHER: 'Erbert.  We live in a bloody swamp.  We need all the land we can get.\\nHERBERT: But-- but I don't like her.\\nFATHER: Don't like her?!  What's wrong with her?!  She's beautiful.  She's rich.  She's got huge...  tracts o' land.\\nHERBERT: I know, but I want the-- the girl that I marry to have...  [music] ... a certain...  special...  something!\\nFATHER: Cut that out!  Cut that out!  Look, you're marrying Princess Lucky, so you'd better get used to the idea! [smack] Guards!  Make sure the Prince doesn't leave this room until I come and get him.\\nGUARD #1: Not to leave the room even if you come and get him.\\nGUARD #2: Hic!\\nFATHER: No, no.  Until I come and get him.\\nGUARD #1: Until you come and get him, we're not to enter the room.\\nFATHER: No, no.  No.  You stay in the room and make sure he doesn't leave.\\nGUARD #1: And you'll come and get him.\\nGUARD #2: Hic!\\nFATHER: Right.\\nGUARD #1: We don't need to do anything, apart from just stop him entering the room.\\nFATHER: No, no.  Leaving the room.\\nGUARD #1: Leaving the room.  Yes. [sniff] \\nFATHER: All right?\\nGUARD #1: Right.\\nGUARD #2: Hic!\\nFATHER: Right.\\nGUARD #1: Oh, if-- if-- if-- uhh-- if-- if-- w-- ehh-- i-- if-- if we--\\nFATHER: Yes?  What is it?\\nGUARD #1: Oh, i-- if-- i-- oh--\\nFATHER: Look, it's quite simple.\\nGUARD #1: Uh...\\nFATHER: You just stay here, and make sure 'e doesn't leave the room.  Alright?\\nGUARD #2: Hic!\\nFATHER: Right.\\nGUARD #1: Oh, I remember.  Uhh, can he leave the room with us?\\nFATHER: N-- no no.  No.  You just keep him in here, and make sure he--\\nGUARD #1: Oh, yes.  We'll keep him in here, obviously.  But if he had to leave and we were with him--\\nFATHER: No, no, no, no.  Just keep him in here--\\nGUARD #1: Until you, or anyone else--\\nFATHER: No, not anyone else.  Just me.\\nGUARD #1: Just you.\\nGUARD #2: Hic!\\nFATHER: Get back.\\nGUARD #1: Get back.\\nFATHER: All right?\\nGUARD #1: Right.  We'll stay here until you get back.\\nGUARD #2: Hic!\\nFATHER: And, uh, make sure he doesn't leave.\\nGUARD #1: What?\\nFATHER: Make sure 'e doesn't leave.\\nGUARD #1: The Prince?\\nFATHER: Yes.  Make sure 'e doesn't leave.\\nGUARD #1: Oh, yes, of course.  \\nGUARD #2: Hic!\\nGUARD #1: Ah.  I thought you meant him.  You know, it seemed a bit daft me havin' to guard him when he's a guard.\\nFATHER: Is that clear?\\nGUARD #2: Hic!\\nGUARD #1: Oh, quite clear.  No problems.\\nFATHER: Right.  Where are you going?\\nGUARD #1: We're coming with you.\\nFATHER: No, no.  I want you to stay here and make sure 'e doesn't leave.\\nGUARD #1: Oh, I see.  Right.\\nHERBERT: But Father!\\nFATHER: Shut your noise, you!  And get that suit on! [music] And no singing!\\nGUARD #2: Hic!\\nFATHER: Oh, go and get a glass of water. [clank] [scribble scribble scribble fold fold] [twong]\\nSCENE 15:\\nLAUNCELOT: Well taken, Concorde!\\nCONCORDE: Thank you, sir!  Most kind.\\nLAUNCELOT: And again!  Over we go!  Good.  Steady!  And now, the big one!  Uuh!  Come on, Concorde! [thwonk] \\nCONCORDE: Message for you, sir. [fwump] \\nLAUNCELOT: Concorde!  Concorde!  Speak to me!  'To whoever finds this note: I have been imprisoned by my father, who wishes me to marry against my will.  Please, please, please come and rescue me.  I am in the Tall Tower of Swamp Castle.' At last!  A call!  A cry of distress!  This could be the sign that leads us to the Holy Grail!  Brave, brave Concorde, you shall not have died in vain!\\nCONCORDE: Uh, I'm-- I'm not quite dead, sir.\\nLAUNCELOT: Well, you shall not have been mortally wounded in vain!\\nCONCORDE: I-- I-- I think I c-- I could pull through, sir.\\nLAUNCELOT: Oh, I see.\\nCONCORDE: Actually, I think I'm all right to come with you, sir--\\nLAUNCELOT: No, no, sweet Concorde!  Stay here!  I will send help as soon as I have accomplished a daring and heroic rescue in my own particular...  [sigh] \\nCONCORDE: Idiom, sir?\\nLAUNCELOT: Idiom!\\nCONCORDE: No, I feel fine, actually, sir.\\nLAUNCELOT: Farewell, sweet Concorde!\\nCONCORDE: I'll, um, I'll just stay here then.  Shall I, sir?  Yeah\\nSCENE 16: [inside castle] \\nPRINCESS LUCKY and GIRLS: [giggle giggle giggle] [outside castle] \\nGUEST: 'Morning!\\nSENTRY #1: 'Morning.\\nSENTRY #2: Oooh.\\nSENTRY #1: [ptoo] \\nLAUNCELOT: Ha ha!  Hiyya!\\nSENTRY #2: Hey!\\nLAUNCELOT: Hiyya!, Ha!, etc.\\nPRINCESS LUCKY and GIRLS: [giggle giggle giggle] \\nLAUNCELOT: Ha ha!  Huy!\\nGUESTS: Uuh!  Aaah!\\nLAUNCELOT: Ha ha!  And take this!  Aah!  Hiyah!  Aah!  Aaah!  Hyy!  Hya!  Hiyya!  Ha! ...\\nGUARD #1: Now, you're not allowed to enter the room-- aaugh!\\nLAUNCELOT: O fair one, behold your humble servant Sir Launcelot of Camelot.  I have come to take y-- Oh, I'm terribly sorry.\\nHERBERT: You got my note!\\nLAUNCELOT: Uh, well, I-- I got a-- a note.\\nHERBERT: You've come to rescue me!\\nLAUNCELOT: Uh, well, no.  You see, I hadn't--\\nHERBERT: I knew someone would.  I knew that somewhere out there...  [music] \\nLAUNCELOT: Well, I--\\nHERBERT: ... there must be...  someone...\\nFATHER: Stop that!  Stop that!  Stop it!  Stop it!  Who are you?\\nHERBERT: I'm your son!\\nFATHER: No, not you.\\nLAUNCELOT: Uh, I am Sir Launcelot, sir.\\nHERBERT: He's come to rescue me, Father.\\nLAUNCELOT: Well, let's not jump to conclusions.\\nFATHER: Did you kill all those guards?\\nLAUNCELOT: Uh...  Oh, yes.  Sorry.\\nFATHER: They cost fifty pounds each!\\nLAUNCELOT: Well, I'm awfully sorry.  Um, I really can explain everything.\\nHERBERT: Don't be afraid of him, Sir Launcelot.  I've got a rope all ready.\\nFATHER: You killed eight wedding guests in all!\\nLAUNCELOT: Well, uh, you see, the thing is, I thought your son was a lady.\\nFATHER: I can understand that.\\nHERBERT: Hurry, Sir Launcelot!  Hurry!\\nFATHER: Shut up!  You only killed the bride's father, that's all!\\nLAUNCELOT: Well, I really didn't mean to...\\nFATHER: Didn't mean to?!  You put your sword right through his head!\\nLAUNCELOT: Oh, dear.  Is he all right?\\nFATHER: You even kicked the bride in the chest!  This is going to cost me a fortune!\\nLAUNCELOT: Well, I can explain.  I was in the forest, um, riding north from Camelot, when I got this note, you see--\\nFATHER: Camelot?  Are you from, uh, Camelot?\\nHERBERT: Hurry, Sir Launcelot!\\nLAUNCELOT: Uh, I am a Knight of King Arthur, sir.\\nFATHER: Very nice castle, Camelot.  Uh, very good pig country...\\nLAUNCELOT: Is it?\\nHERBERT: Hurry!  I'm ready!\\nFATHER: Would you, uh, like to come and have a drink?\\nLAUNCELOT: Well, that-- that's, uh, awfully nice of you, ...\\nHERBERT: I am ready!\\nLAUNCELOT: ... um, I mean to be so understanding. [thonk] Um, ... [woosh] \\nHERBERT: Oooh!\\nLAUNCELOT: ... I'm afraid when I'm in this idiom, I sometimes get a bit, uh, sort of carried away.\\nFATHER: Oh, don't worry about that.\\nHERBERT: Oooh! [splat] \\nSCENE 17:\\nGUESTS: [crying] \\nFATHER: Well, this is the main hall.  We're going to have all this knocked through, and made into one big, uh, living room.\\nGUEST: There he is!\\nFATHER: Oh, bloody hell.\\nLAUNCELOT: Ha ha ha!  Hey!  Ha ha!\\nFATHER: Hold it!  Stop it!  Hold it!  Hold it!  Hold it!  Hold it!  Hold it!  Please!\\nLAUNCELOT: Sorry.  Sorry.  You see what I mean?  I just get carried away.  I'm really most awfully sorry.  Sorry!  Sorry, everyone.\\nGUEST #1: He's killed the best man!\\nGUESTS: [yelling] \\nFATHER: Hold it!  Hold it!  Please!  Hold it!  This is Sir Launcelot from the Court of Camelot, a very brave and influential knight, and my special guest here today.\\nLAUNCELOT: Hello.\\nGUEST: He killed my auntie!\\nGUESTS: [yelling] \\nFATHER: Please!  Please!  This is supposed to be a happy occasion!  Let's not bicker and argue about who killed who.  We are here today to witness the union of two young people in the joyful bond of the holy wedlock.  Unfortunately, one of them, my son Herbert, has just fallen to his death.\\nGUESTS: Oh!  Oh no!\\nFATHER: But I don't want to think I've not lost a son, so much as...  gained a daughter! [clap clap clap] For, since the tragic death of her father--\\nGUEST #2: He's not quite dead!\\nFATHER: Since the near fatal wounding of her father--\\nGUEST #2: He's getting better!\\nFATHER: For, since her own father, who, when he seemed about to recover, suddenly felt the icy hand of death upon him.\\nBRIDE'S FATHER: Uugh!\\nGUEST #2: Oh, he's died!\\nFATHER: And I want his only daughter to look upon me as her old dad, in a very real, and legally binding sense. [clap clap clap] And I feel sure that the merger-- er, the union between the Princess and the brave, but dangerous, Sir Launcelot of Camelot--\\nLAUNCELOT: What?\\nGUEST #2: Look!  The dead Prince!\\nGUESTS: Oooh!  The dead Prince!\\nCONCORDE: He's not quite dead.\\nHERBERT: No, I feel much better.\\nFATHER: You fell out of the Tall Tower, you creep!\\nHERBERT: No, I was saved at the last minute.\\nFATHER: How?!\\nHERBERT: Well, I'll tell you. [music] \\nFATHER: Not like that!  Not like that!  No!  Stop it!\\nGUESTS: [singing] He's going to tell!  He's going to tell! ...\\nFATHER: Shut uuup!\\nGUESTS: [singing] He's going to tell! ...\\nFATHER: Shut up!\\nGUESTS: [singing] He's going to tell! ...\\nFATHER: Shut up!\\nGUESTS: [singing] He's going to tell! ...\\nFATHER: Not like that!\\nGUESTS: [singing] He's going to tell!  He's going to tell!  He's going to tell!  He's going to tell! ...\\nCONCORDE: Quickly, sir!\\nGUESTS: [singing] He's going to tell! ...\\nCONCORDE: Come this way!\\nGUESTS: [singing] He's going to tell!  He's going to tell! ...\\nLAUNCELOT: No!  It's not right for my idiom!\\nGUESTS: [singing] He's going to tell about his great escape...\\nLAUNCELOT: I must escape more...  [sigh] \\nGUESTS: [singing] Oh, he fell a long, long way...\\nCONCORDE: Dramatically, sir?\\nLAUNCELOT: Dramatically!\\nGUESTS: [singing] But he's here with us today...\\nLAUNCELOT: Heee!  Hoa! [crash] Hoo!\\nGUESTS: [singing] What a wonderful escape!\\nLAUNCELOT: Excuse me.  Could, uh-- could somebody give me a push, please\\nSCENE 18: [King Arthur music] [clop clop clop] [rewr!  rewr!  rewr!  rewr!  rewr!  rewr!] \\nARTHUR: Old crone! [rewr!] [music stops] Is there anywhere in this town where we could buy a shrubbery? [dramatic chord] \\nOLD CRONE: Who sent you?\\nARTHUR: The Knights Who Say 'Ni'.\\nCRONE: Aggh!  No!  Never!  We have no shrubberies here.\\nARTHUR: If you do not tell us where we can buy a shrubbery, my friend and I will say...  we will say...  'ni'.\\nCRONE: Agh!  Do your worst!\\nARTHUR: Very well!  If you will not assist us voluntarily, ...  ni!\\nCRONE: No!  Never!  No shrubberies!\\nARTHUR: Ni!\\nCRONE: [cough] \\nBEDEVERE: Nu!\\nARTHUR: No, no, no, no...\\nBEDEVERE: Nu!\\nARTHUR: No, it's not that, it's 'ni'.\\nBEDEVERE: Nu!\\nARTHUR: No, no-- 'ni'.  You're not doing it properly.  No.\\nBEDEVERE: Ni!\\nARTHUR and BEDEVERE: Ni!\\nARTHUR: That's it.  That's it.  You've got it.\\nARTHUR and BEDEVERE: Ni!\\nCRONE: Ohh!\\nBEDEVERE: Ni!\\nARTHUR: Ni!\\nCRONE: Agh!\\nBEDEVERE: Ni!\\nARTHUR: Ni!\\nBEDEVERE: Ni!\\nARTHUR: Ni!\\nBEDEVERE: Ni!\\nROGER THE SHRUBBER: Are you saying 'ni' to that old woman?\\nARTHUR: Erm, yes.\\nROGER: Oh, what sad times are these when passing ruffians can 'ni' at will to old ladies.  There is a pestilence upon this land.  Nothing is sacred. Even those who arrange and design shrubberies are under considerable economic stress at this period in history.\\nARTHUR: Did you say 'shrubberies'?\\nROGER: Yes.  Shrubberies are my trade.  I am a shrubber.  My name is Roger the Shrubber.  I arrange, design, and sell shrubberies.\\nBEDEVERE: Ni!\\nARTHUR: No!  No, no, no!  No\\nSCENE 19:\\nARTHUR: O Knights of Ni, we have brought you your shrubbery.  May we go now?\\nHEAD KNIGHT: It is a good shrubbery.  I like the laurels particularly.  But there is one small problem.\\nARTHUR: What is that?\\nHEAD KNIGHT: We are now...  no longer the Knights Who Say 'Ni'.\\nKNIGHTS OF NI: Ni!  Shh!\\nHEAD KNIGHT: Shh!  We are now the Knights Who Say 'Ecky-ecky-ecky-ecky-pikang-zoop-boing-goodem-zoo-owli-zhiv'.\\nRANDOM: Ni!\\nHEAD KNIGHT: Therefore, we must give you a test.\\nARTHUR: What is this test, O Knights of-- Knights Who 'Til Recently Said 'Ni'?\\nHEAD KNIGHT: Firstly, you must find...  another shrubbery! [dramatic chord] \\nARTHUR: Not another shrubbery!\\nRANDOM: Ni!\\nHEAD KNIGHT: Then, when you have found the shrubbery, you must place it here beside this shrubbery, only slightly higher so you get the two-level effect with a little path running down the middle.\\nKNIGHTS OF NI: A path!  A path!  A path!  Ni!  Shh!  Ni!  Ni!  Ni!  Shh!  Shh! ...\\nHEAD KNIGHT: Then, when you have found the shrubbery, you must cut down the mightiest tree in the forest...  with...  a herring! [dramatic chord] \\nARTHUR: We shall do no such thing!\\nHEAD KNIGHT: Oh, please!\\nARTHUR: Cut down a tree with a herring?  It can't be done.\\nKNIGHTS OF NI: Aaaugh!  Aaaugh!\\nHEAD KNIGHT: Augh!  Ohh!  Don't say that word.\\nARTHUR: What word?\\nHEAD KNIGHT: I cannot tell, suffice to say is one of the words the Knights of Ni cannot hear.\\nARTHUR: How can we not say the word if you don't tell us what it is?\\nKNIGHTS OF NI: Aaaaugh!\\nHEAD KNIGHT: You said it again!\\nARTHUR: What, 'is'?\\nKNIGHTS OF NI: Agh!  No, not 'is'.\\nHEAD KNIGHT: No, not 'is'.  You wouldn't get vary far in life not saying 'is'.\\nKNIGHTS OF NI: No, not 'is'.  Not 'is'.\\nBEDEVERE: My liege, it's Sir Robin!\\nMINSTREL: [singing] Packing it in and packing it up, And sneaking away and buggering up, And chickening out and pissing off home, Yes, bravely he is throwing in the sponge.\\nARTHUR: Sir Robin!\\nROBIN: My liege!  It's good to see you.\\nHEAD KNIGHT: Now he's said the word!  \\nARTHUR: Surely you've not given up your quest for the Holy Grail?\\nMINSTREL: [singing] He is sneaking away and buggering up--\\nROBIN: Shut up!  No, no.  No.  Far from it.\\nHEAD KNIGHT: He said the word again!\\nKNIGHTS OF NI: Aaaaugh!\\nROBIN: I was looking for it.\\nKNIGHTS OF NI: Aaaaugh!\\nROBIN: Uh, here-- here in this forest.\\nARTHUR: No, it is far from this place.\\nKNIGHTS OF NI: Aaaaugh!\\nHEAD KNIGHT: Aaaaugh!  Stop saying the word!  The word...\\nARTHUR: Oh, stop it!\\nKNIGHTS OF NI: ... we cannot hear!\\nHEAD KNIGHT: Ow!  He said it again!\\nARTHUR: Patsy!\\nHEAD KNIGHT: Wait!  I said it!  I said it! [clop clop clop] Ooh!  I said it again!  And there again!  That's three 'it's!  Ohh!\\nKNIGHTS OF NI: Aaaaugh\\nNARRATOR: And so, Arthur and Bedevere and Sir Robin set out on their search to find the enchanter of whom the old man had spoken in scene twenty-four.  Beyond the forest they met Launcelot and Galahad, and there was much rejoicing.\\nKNIGHTS: Yay!  Yay! [woosh] \\nNARRATOR: In the frozen land of Nador, they were forced to eat Robin's minstrels.\\nMINSTREL: [high-pitched] Get back!  Eee!\\nNARRATOR: And there was much rejoicing.\\nKNIGHTS: Yay!\\nNARRATOR: A year passed.\\nCARTOON CHARACTER: [shivering] \\nNARRATOR: Winter changed into Spring.\\nCARTOON CHARACTER: Mmm, nice.\\nNARRATOR: Spring changed into Summer.\\nCARTOON CHARACTER: Oh.  Ahh.\\nNARRATOR: Summer changed back into Winter.\\nCARTOON CHARACTER: Oh?\\nNARRATOR: And Winter gave Spring and Summer a miss and went straight on into Autumn.\\nCARTOON CHARACTER: Aah. [snap] Oh!  Waa!\\nNARRATOR: Until one day..\\nSCENE 20: [King Arthur music] [clop clop clop] [music stops] [boom] \\nKNIGHTS: Eh.  Oh.  See it?  Oh.  Oh.\\nARTHUR: Knights!  Forward! [boom boom boom boom boom] [squeak] [boom boom boom boom] What manner of man are you that can summon up fire without flint or tinder?\\nTIM THE ENCHANTER: I...  am an enchanter.\\nARTHUR: By what name are you known?\\nTIM: There are some who call me...  Tim?\\nARTHUR: Greetings, Tim the Enchanter.\\nTIM: Greetings, King Arthur!\\nARTHUR: You know my name?\\nTIM: I do. [zoosh] You seek the Holy Grail!\\nARTHUR: That is our quest.  You know much that is hidden, O Tim.\\nTIM: Quite. [pweeng boom] [clap clap clap] \\nROBIN: Oh.\\nARTHUR: Yes, we're-- we're looking for the Holy Grail.  Our quest is to find the Holy Grail.\\nKNIGHTS: Yeah.  Yes.  It is.  It is.  Yeah.  Yup.  Yup.  Hm.\\nARTHUR: And so we're-- we're-- we're-- we're looking for it.\\nBEDEVERE: Yes, we are.\\nGALAHAD: Yeah.  \\nROBIN: We are.  We are.\\nBEDEVERE: We have been for some time.\\nROBIN: Ages.\\nBEDEVERE: Umhm.\\nARTHUR: Uh-- uh, so, uh, anything that you could do to, uh-- to help, would be...  very...  helpful.\\nGALAHAD: Look, can you tell us where-- [boom] \\nARTHUR: Fine.  Um, I don't want to waste any more of your time, but, uh, I don't suppose you could, uh, tell us where we might find a, um-- find a, uh-- a, um-- a, uh--\\nTIM: A what...?\\nARTHUR: A g-- a-- a g-- a g-- a-- a g--\\nTIM: A grail?!\\nARTHUR: Yes, I think so.\\nROBIN: Y-- y-- yes.\\nARTHUR: Yes.\\nGALAHAD: Yup.\\nKNIGHTS: That's it...\\nTIM: Yes!\\nROBIN: Oh.\\nARTHUR: Oh.  Thank you.\\nROBIN: Ahh.\\nGALAHAD: Oh.  Fine.\\nARTHUR: Thank you.\\nROBIN: Splendid.\\nKNIGHTS: Aah... [boom pweeng boom boom] \\nARTHUR: Look, um, you're a busy man, uh--\\nTIM: Yes, I can help you find the Holy Grail.\\nKNIGHTS: Oh, thank you.  Oh...\\nTIM: To the north there lies a cave-- the cave of Caerbannog-- wherein, carved in mystic runes upon the very living rock, the last words of Olfin Bedwere of Rheged... [boom] ... make plain the last resting place of the most Holy Grail.\\nARTHUR: Where could we find this cave, O Tim?\\nTIM: Follow.  But!  Follow only if ye be men of valor, for the entrance to this cave is guarded by a creature so foul, so cruel that no man yet has fought with it and lived!  Bones of full fifty men lie strewn about its lair.  So, brave knights, if you do doubt your courage or your strength, come no further, for death awaits you all with nasty, big, pointy teeth.\\nARTHUR: What an eccentric performance\\nSCENE 21: [clop clop clop] [whinny whinny] \\nGALAHAD: They're nervous, sire.\\nARTHUR: Then we'd best leave them here and carry on on foot.  Dis-mount!\\nTIM: Behold the cave of Caerbannog!\\nARTHUR: Right!  Keep me covered.\\nGALAHAD: What with?\\nARTHUR: W-- just keep me covered.\\nTIM: Too late! [dramatic chord] \\nARTHUR: What?\\nTIM: There he is!\\nARTHUR: Where?\\nTIM: There!\\nARTHUR: What, behind the rabbit?\\nTIM: It is the rabbit!\\nARTHUR: You silly sod!\\nTIM: What?\\nARTHUR: You got us all worked up!\\nTIM: Well, that's no ordinary rabbit.\\nARTHUR: Ohh.\\nTIM: That's the most foul, cruel, and bad-tempered rodent you ever set eyes on.\\nROBIN: You tit!  I soiled my armor I was so scared!\\nTIM: Look, that rabbit's got a vicious streak a mile wide; it's a killer!\\nGALAHAD: Get stuffed!\\nTIM: He'll do you up a treat mate!\\nGALAHAD: Oh, yeah?\\nROBIN: You mangy scots git!\\nTIM: I'm warning you!\\nROBIN: What's he do, nibble your bum?\\nTIM: He's got huge, sharp-- eh-- he can leap about-- look at the bones!\\nARTHUR: Go on, Bors.  Chop his head off!\\nBORS: Right!  Silly little bleeder.  One rabbit stew comin' right up!\\nTIM: Look! [squeak] \\nBORS: Aaaugh! [dramatic chord] [clunk] \\nARTHUR: Jesus Christ!\\nTIM: I warned you!\\nROBIN: I done it again!\\nTIM: I warned you, but did you listen to me?  Oh, no, you knew it all, didn't you?  Oh, it's just a harmless little bunny, isn't it?  Well, it's always the same.  I always tell them--\\nARTHUR: Oh, shut up!\\nTIM: Do they listen to me?\\nARTHUR: Right!\\nTIM: Oh, no...\\nKNIGHTS: Charge! [squeak squeak squeak] \\nKNIGHTS: Aaaaugh!, Aaaugh!, etc.\\nARTHUR: Run away!  Run away!\\nKNIGHTS: Run away!  Run away! ...\\nTIM: Ha ha ha ha!  Ha haw haw!  Ha!  Ha ha!\\nARTHUR: Right.  How many did we lose?\\nLAUNCELOT: Gawain.\\nGALAHAD: Ector.\\nARTHUR: And Bors.  That's five.\\nGALAHAD: Three, sir.\\nARTHUR: Three.  Three.  And we'd better not risk another frontal assault.  That rabbit's dynamite.\\nROBIN: Would it help to confuse it if we run away more?\\nARTHUR: Oh, shut up and go and change your armor.\\nGALAHAD: Let us taunt it!  It may become so cross that it will make a mistake.\\nARTHUR: Like what?\\nGALAHAD: Well...  ooh.\\nLAUNCELOT: Have we got bows?\\nARTHUR: No.\\nLAUNCELOT: We have the Holy Hand Grenade.\\nARTHUR: Yes, of course!  The Holy Hand Grenade of Antioch!  'Tis one of the sacred relics Brother Maynard carries with him!  Brother Maynard!  Bring up the Holy Hand Grenade!\\nMONKS: [chanting] Pie Iesu domine, dona eis requiem.  Pie Iesu domine, donaeis requiem.  Pie Iesu domine, dona eis requiem.  Pie Iesu domine, dona eisrequiem.\\nARTHUR: How does it, um-- how does it work?\\nLAUNCELOT: I know not, my liege.\\nARTHUR: Consult the Book of Armaments!\\nBROTHER MAYNARD: Armaments, Chapter Two, verses Nine to Twenty-one.\\nSECOND BROTHER: And Saint Attila raised the hand grenade up on high, saying,'O Lord, bless this thy hand grenade that with it thou mayest blow thine enemies to tiny bits, in thy mercy.' And the Lord did grin, and the people did feast upon the lambs and sloths and carp and anchovies and orangutans and breakfast cereals and fruit bats and large chu--\\nMAYNARD: Skip a bit, Brother.\\nSECOND BROTHER: And the Lord spake, saying, 'First shalt thou take out the Holy Pin.  Then, shalt thou count to three, no more, no less.  Three shalt be the number thou shalt count, and the number of the counting shall be three.  Four shalt thou not count, nor either count thou two, excepting that thou then proceed to three.  Five is right out.  Once the number three, being the third number, be reached, then lobbest thou thy Holy Hand Grenade of Antioch towards thy foe, who, being naughty in my sight, shall snuff it.'\\nMAYNARD: Amen.\\nKNIGHTS: Amen.\\nARTHUR: Right!  One...  two...  five!\\nGALAHAD: Three, sir!\\nARTHUR: Three! [angels sing] [boom] \\nSCENE 22:\\nARTHUR: There!  Look!\\nLAUNCELOT: What does it say?\\nGALAHAD: What language is that?\\nARTHUR: Brother Maynard!  You are a scholar.\\nMAYNARD: It's Aramaic!\\nGALAHAD: Of course!  Joseph of Arimathea!\\nLAUNCELOT: 'Course!\\nARTHUR: What does it say?\\nMAYNARD: It reads, 'Here may be found the last words of Joseph of Arimathea.  He who is valiant and pure of spirit may find the Holy Grail in the Castle of uuggggggh'.\\nARTHUR: What?\\nMAYNARD: '...  the Castle of uuggggggh'.\\nBEDEVERE: What is that?\\nMAYNARD: He must have died while carving it.\\nLAUNCELOT: Oh, come on!\\nMAYNARD: Well, that's what it says.\\nARTHUR: Look, if he was dying, he wouldn't bother to carve 'aaggggh'.  He'd just say it!\\nMAYNARD: Well, that's what's carved in the rock!\\nGALAHAD: Perhaps he was dictating.\\nARTHUR: Oh, shut up.  Well, does it say anything else?\\nMAYNARD: No.  Just, 'uuggggggh'.\\nLAUNCELOT: Aauuggghhh.\\nARTHUR: Aaauggh.\\nBEDEVERE: Do you suppose he meant the Camaaaaaargue?\\nGALAHAD: Where's that?\\nBEDEVERE: France, I think.\\nLAUNCELOT: Isn't there a Saint Aauuuves in Cornwall?\\nARTHUR: No, that's Saint Ives.\\nLAUNCELOT: Oh, yes.  Saint Iiiives.\\nKNIGHTS: Iiiiives.\\nBEDEVERE: Oooohoohohooo!\\nLAUNCELOT: No, no.  'Aauuuuugh', at the back of the throat.  Aauuugh.\\nBEDEVERE: N-- no.  No, no, no, no.  'Oooooooh', in surprise and alarm.\\nLAUNCELOT: Oh, you mean sort of a 'aaaah'!\\nBEDEVERE: Yes, but I-- aaaaaah!\\nARTHUR: Oooh!\\nGALAHAD: My God! [dramatic chord] [roar] \\nMAYNARD: It's the legendary Black Beast of Aaauugh! [Black Beast of Aaauugh eats BROTHER MAYNARD] \\nBEDEVERE: That's it!  That's it!\\nARTHUR: Run away!\\nKNIGHTS: Run away! [roar] Run away!  Run awaaay!  Run awaaaaay! [roar] Keep running! [boom] [roar] Shh!  Shh!  Shh!  Shh!  Shh!  Shh!  Shh!  Shh! ...\\nBEDEVERE: We've lost him. [roar] \\nKNIGHTS: Aagh!\\nNARRATOR: As the horrendous Black Beast lunged forward, escape for Arthur and his knights seemed hopeless, when suddenly, the animator suffered a fatal heart attack.\\nANIMATOR: Ulk! [thump] \\nNARRATOR: The cartoon peril was no more.  The quest for Holy Grail could continue.\\nSCENE 23: [gurgle] \\nGALAHAD: There it is!\\nARTHUR: The Bridge of Death!\\nROBIN: Oh, great.\\nARTHUR: Look!  There's the old man from scene twenty-four!\\nBEDEVERE: What is he doing here?\\nARTHUR: He is the keeper of the Bridge of Death.  He asks each traveller five questions--\\nGALAHAD: Three questions.\\nARTHUR: Three questions.  He who answers the five questions--\\nGALAHAD: Three questions.\\nARTHUR: Three questions may cross in safety.\\nROBIN: What if you get a question wrong?\\nARTHUR: Then you are cast into the Gorge of Eternal Peril.\\nROBIN: Oh, I won't go.\\nGALAHAD: Who's going to answer the questions?\\nARTHUR: Sir Robin!\\nROBIN: Yes?\\nARTHUR: Brave Sir Robin, you go.\\nROBIN: Hey!  I've got a great idea.  Why doesn't Launcelot go?\\nLAUNCELOT: Yes.  Let me go, my liege.  I will take him single-handed.  I shall make a feint to the north-east that s--\\nARTHUR: No, no.  No.  Hang on!  Hang on!  Hang on!  Just answer the five questions--\\nGALAHAD: Three questions.\\nARTHUR: Three questions as best you can.  And we shall watch...  and pray.\\nLAUNCELOT: I understand, my liege.\\nARTHUR: Good luck, brave Sir Launcelot.  God be with you.\\nBRIDGEKEEPER: Stop!  Who would cross the Bridge of Death must answer me these questions three, ere the other side he see.\\nLAUNCELOT: Ask me the questions, bridgekeeper.  I am not afraid.\\nBRIDGEKEEPER: What is your name?\\nLAUNCELOT: My name is Sir Launcelot of Camelot.\\nBRIDGEKEEPER: What is your quest?\\nLAUNCELOT: To seek the Holy Grail.\\nBRIDGEKEEPER: What is your favorite color?\\nLAUNCELOT: Blue.\\nBRIDGEKEEPER: Right.  Off you go.\\nLAUNCELOT: Oh, thank you.  Thank you very much.\\nROBIN: That's easy!\\nBRIDGEKEEPER: Stop!  Who approacheth the Bridge of Death must answer me these questions three, ere the other side he see.\\nROBIN: Ask me the questions, bridgekeeper.  I'm not afraid.\\nBRIDGEKEEPER: What is your name?\\nROBIN: Sir Robin of Camelot.\\nBRIDGEKEEPER: What is your quest?\\nROBIN: To seek the Holy Grail.\\nBRIDGEKEEPER: What is the capital of Assyria?\\nROBIN: I don't know that!  Auuuuuuuugh!\\nBRIDGEKEEPER: Stop!  What is your name?\\nGALAHAD: Sir Galahad of Camelot.\\nBRIDGEKEEPER: What is your quest?\\nGALAHAD: I seek the Grail.\\nBRIDGEKEEPER: What is your favorite color?\\nGALAHAD: Blue.  No yel-- auuuuuuuugh!\\nBRIDGEKEEPER: Hee hee heh.  Stop!  What is your name?\\nARTHUR: It is Arthur, King of the Britons.\\nBRIDGEKEEPER: What is your quest?\\nARTHUR: To seek the Holy Grail.\\nBRIDGEKEEPER: What is the air-speed velocity of an unladen swallow?\\nARTHUR: What do you mean?  An African or European swallow?\\nBRIDGEKEEPER: Huh?  I-- I don't know that!  Auuuuuuuugh!\\nBEDEVERE: How do know so much about swallows?\\nARTHUR: Well, you have to know these things when you're a king, you know. [suspenseful music] [music suddenly stops] [intermission] [suspenseful music resumes]\\nSCENE 24:\\nARTHUR: Launcelot!  Launcelot!  Launcelot!\\nBEDEVERE: Launcelot!  Launcelot!\\nARTHUR: Launcelot! [police radio] Launcelot!\\nBEDEVERE: Launcelot!  Launcelot! [angels sing] [singing stops] [ethereal music] \\nARTHUR: The Castle Aaagh.  Our quest is at an end!  God be praised!  Almighty God, we thank Thee that Thou hast vouchsafed to us the most holy-- [twong] [baaaa] Jesus Christ! [thud] \\nFRENCH GUARD: Allo, dappy English k-niggets and Monsieur Arthur King, who has the brain of a duck, you know.  So, we French fellows outwit you a second time!\\nARTHUR: How dare you profane this place with your presence!  I command you, in the name of the Knights of Camelot, to open the doors of this sacred castle, to which God Himself has guided us!\\nFRENCH GUARD: How you English say, 'I one more time, mac, unclog my nose in your direction', sons of a window-dresser!  So, you think you could out-clever us French folk with your silly knees-bent running about advancing behaviour?!  I wave my private parts at your aunties, you cheesy lot of second hand electric donkey-bottom biters.\\nARTHUR: In the name of the Lord, we demand entrance to this sacred castle!\\nFRENCH GUARD: No chance, English bed-wetting types.  I burst my pimples at you and call your door-opening request a silly thing, you tiny-brained wipers of other people's bottoms!\\nARTHUR: If you do not open this door, we shall take this castle by force! [splat] In the name of God and the glory of our-- [splat] \\nFRENCH GUARDS: [laughing] \\nARTHUR: Agh.  Right!  That settles it!\\nFRENCH GUARD: Yes, depart a lot at this time, and cut the approaching any more or we fire arrows at the tops of your heads and make castanets out of your testicles already!  Ha ha haaa ha!\\nARTHUR: Walk away.  Just ignore them.\\nFRENCH GUARD: And now, remain gone, illegitimate-faced bugger-folk!  And, if you think you got a nasty taunting this time, you ain't heard nothing yet, dappy English k-nnniggets!  Thpppt!\\nFRENCH GUARDS: [taunting] \\nARTHUR: We shall attack at once!\\nBEDEVERE: Yes, my liege!\\nARTHUR: Stand by for attack! [exciting music] [music stops] [silence] French persons!\\nFRENCH GUARDS: [taunting] ... Dappy! ...\\nARTHUR: Today the blood of many a valiant knight shall be avenged.  In the name of God, ...\\nFRENCH GUARDS: Hoo hoo!  Ohh, ha ha ha ha ha! ...\\nARTHUR: ... we shall not stop our fight 'til each one of you lies dead, and the Holy Grail returns to those whom God has chosen!\\nFRENCH GUARDS: ... Ha ha ha! ...\\nARTHUR: Charge!\\nARMY OF KNIGHTS: Hooray! [police siren] \\nHISTORIAN'S WIFE: Yes.  They're the ones.  I'm sure.\\nINSPECTOR: Come on.  Anybody armed must go too.\\nOFFICER #1: All right.  Come on.  Back.\\nHISTORIAN'S WIFE: Get that one.\\nOFFICER #1: Back.  Right away.  Just...  pull it off.  Come on.  Come along.\\nINSPECTOR: Put this man in the van.\\nOFFICER #1: Clear off.  Come on.\\nBEDEVERE: With whom?\\nINSPECTOR: Which one?\\nOFFICER #1: Oh-- this one.\\nINSPECTOR: Come on.  Put him in the van.\\nOFFICER #2: Get a blanket.\\nOFFICER #1: We have no hospital.\\nRANDOM: Ahh. [squeak] \\nRANDOM: Ooh.\\nOFFICER #1: Come on.  Back.  Riiight back.  Come on!\\nOFFICER #2: Run along!  Run along!\\nOFFICER #1: Pull that off.  My, that's an offensive weapon, that is.\\nOFFICER #2: Come on.  Back with 'em.  Back.  Right.  Come along.\\nINSPECTOR: Everything? [squeak] \\nOFFICER #1: All right, sonny.  That's enough.  Just pack that in. [crash] \\nCAMERAMAN: Christ!\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(holy_grail)\n",
    "holy_grail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADd1JREFUeJzt3H+o3Xd9x/Hna4m2tjJN10uISdjNH0FJBVcJXdUhYxFa\nrZj+VTLoCKPQf7pZRZBk/iH7I9CBiP6xCqHqwhRLqGUNKs4uKrJ/2t1a2ZrErJlpTWLSXDf8Mf9o\nbX3vj/N1nJbe3HObe3p63z4fEM73+z2fc7+fD2mf95vvPfekqpAk9fV7s56AJGm6DL0kNWfoJak5\nQy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpObWz3oCANdee23Nz8/PehqStKY89thjP62queXGvSZC\nPz8/z8LCwqynIUlrSpKnJxnnrRtJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0Zeklq\n7jXxm7GXa37f12dy3qfuuWUm55WklfCKXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtS\nc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWp\nuYlCn+SjSY4leSLJV5JcmeSaJA8neXJ43DA2fn+SU0lOJrlpetOXJC1n2dAn2Qx8GNhZVW8H1gF7\ngH3A0araDhwd9kmyY3j+OuBm4N4k66YzfUnScia9dbMeeEOS9cBVwE+A3cCh4flDwK3D9m7g/qp6\ntqpOA6eAG1ZvypKklVg29FV1DvgU8GPgPPDzqvoWsLGqzg/DLgAbh+3NwJmxL3F2OCZJmoFJbt1s\nYHSVvg14C3B1ktvHx1RVAbWSEye5M8lCkoXFxcWVvFSStAKT3Lp5H3C6qhar6tfAg8C7gWeSbAIY\nHi8O488BW8dev2U49iJVdbCqdlbVzrm5uctZgyTpEiYJ/Y+BG5NclSTALuAEcATYO4zZCzw0bB8B\n9iS5Isk2YDvw6OpOW5I0qfXLDaiqR5I8AHwfeB54HDgIvBE4nOQO4GngtmH8sSSHgePD+Luq6oUp\nzV+StIxlQw9QVZ8EPvmSw88yurp/ufEHgAOXNzVJ0mrwN2MlqTlDL0nNGXpJas7QS1Jzhl6SmjP0\nktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6\nSWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9\nJDVn6CWpOUMvSc0ZeklqztBLUnMThT7Jm5M8kOSHSU4keVeSa5I8nOTJ4XHD2Pj9SU4lOZnkpulN\nX5K0nEmv6D8LfLOq3ga8AzgB7AOOVtV24OiwT5IdwB7gOuBm4N4k61Z74pKkySwb+iRvAt4LfB6g\nqp6rqp8Bu4FDw7BDwK3D9m7g/qp6tqpOA6eAG1Z74pKkyUxyRb8NWAS+mOTxJPcluRrYWFXnhzEX\ngI3D9mbgzNjrzw7HJEkzMEno1wPvBD5XVdcDv2K4TfNbVVVAreTESe5MspBkYXFxcSUvlSStwCSh\nPwucrapHhv0HGIX/mSSbAIbHi8Pz54CtY6/fMhx7kao6WFU7q2rn3NzcK52/JGkZy4a+qi4AZ5K8\ndTi0CzgOHAH2Dsf2Ag8N20eAPUmuSLIN2A48uqqzliRNbP2E4/4a+HKS1wM/Av6S0TeJw0nuAJ4G\nbgOoqmNJDjP6ZvA8cFdVvbDqM5ckTWSi0FfVD4CdL/PUriXGHwAOXMa8JEmrxN+MlaTmDL0kNWfo\nJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0\nktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6\nSWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJam7i0CdZl+TxJF8b9q9J8nCSJ4fH\nDWNj9yc5leRkkpumMXFJ0mRWckV/N3BibH8fcLSqtgNHh32S7AD2ANcBNwP3Jlm3OtOVJK3URKFP\nsgW4Bbhv7PBu4NCwfQi4dez4/VX1bFWdBk4BN6zOdCVJKzXpFf1ngI8Dvxk7trGqzg/bF4CNw/Zm\n4MzYuLPDsRdJcmeShSQLi4uLK5u1JGliy4Y+yQeBi1X12FJjqqqAWsmJq+pgVe2sqp1zc3Mreakk\naQXWTzDmPcCHknwAuBL4/SRfAp5JsqmqzifZBFwcxp8Dto69fstwTJI0A8te0VfV/qraUlXzjH7I\n+u2quh04Auwdhu0FHhq2jwB7klyRZBuwHXh01WcuSZrIJFf0S7kHOJzkDuBp4DaAqjqW5DBwHHge\nuKuqXrjsmUqSXpEVhb6qvgt8d9j+b2DXEuMOAAcuc26SpFXgb8ZKUnOGXpKaM/SS1Jyhl6TmDL0k\nNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6S\nmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9J\nzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOaWDX2SrUm+k+R4kmNJ7h6OX5Pk4SRPDo8bxl6zP8mpJCeT\n3DTNBUiSLm2SK/rngY9V1Q7gRuCuJDuAfcDRqtoOHB32GZ7bA1wH3Azcm2TdNCYvSVresqGvqvNV\n9f1h+5fACWAzsBs4NAw7BNw6bO8G7q+qZ6vqNHAKuGG1Jy5JmsyK7tEnmQeuBx4BNlbV+eGpC8DG\nYXszcGbsZWeHY5KkGZg49EneCHwV+EhV/WL8uaoqoFZy4iR3JllIsrC4uLiSl0qSVmCi0Cd5HaPI\nf7mqHhwOP5Nk0/D8JuDicPwcsHXs5VuGYy9SVQeramdV7Zybm3ul85ckLWOSd90E+Dxwoqo+PfbU\nEWDvsL0XeGjs+J4kVyTZBmwHHl29KUuSVmL9BGPeA/wF8B9JfjAc+xvgHuBwkjuAp4HbAKrqWJLD\nwHFG79i5q6peWPWZS5Imsmzoq+pfgSzx9K4lXnMAOHAZ85IkrZJJrui1hPl9X5/JeZ+655aZnFfS\n2uRHIEhSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9\nJDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Ze\nkpoz9JLU3PpZT0ArN7/v6zM791P33DKzc0t6Zbyil6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc769\nUisyq7d2+rZO6ZWb2hV9kpuTnExyKsm+aZ1HknRpUwl9knXA3wPvB3YAf55kxzTOJUm6tGndurkB\nOFVVPwJIcj+wGzg+pfOpOX8bWHrlphX6zcCZsf2zwB9P6VzSVM3ym8zvmll9U+1+ITGzH8YmuRO4\nc9j93yQnL+PLXQv89PJntSa41p5cK5C/e5VnMn3L/r1e5pr/cJJB0wr9OWDr2P6W4dj/q6qDwMHV\nOFmSharauRpf67XOtfbkWnt6rax1Wu+6+Tdge5JtSV4P7AGOTOlckqRLmMoVfVU9n+SvgH8G1gFf\nqKpj0ziXJOnSpnaPvqq+AXxjWl//JVblFtAa4Vp7cq09vSbWmqqa9RwkSVPkZ91IUnNrOvSdP2Yh\nydYk30lyPMmxJHcPx69J8nCSJ4fHDbOe62pJsi7J40m+Nuy3XGuSNyd5IMkPk5xI8q7Ga/3o8N/v\nE0m+kuTKTmtN8oUkF5M8MXZsyfUl2T/06mSSm16tea7Z0P8OfMzC88DHqmoHcCNw17C+fcDRqtoO\nHB32u7gbODG233WtnwW+WVVvA97BaM3t1ppkM/BhYGdVvZ3RGzP20Gut/wDc/JJjL7u+4f/fPcB1\nw2vuHTo2dWs29Ix9zEJVPQf89mMWWqiq81X1/WH7l4xisJnRGg8Nww4Bt85mhqsryRbgFuC+scPt\n1prkTcB7gc8DVNVzVfUzGq51sB54Q5L1wFXAT2i01qr6HvA/Lzm81Pp2A/dX1bNVdRo4xahjU7eW\nQ/9yH7OweUZzmaok88D1wCPAxqo6Pzx1Adg4o2mtts8AHwd+M3as41q3AYvAF4fbVPcluZqGa62q\nc8CngB8D54GfV9W3aLjWl1hqfTNr1loO/e+EJG8Evgp8pKp+Mf5cjd4ytebfNpXkg8DFqnpsqTFd\n1sroCvedwOeq6nrgV7zk1kWXtQ73pncz+ub2FuDqJLePj+my1qW8Vta3lkO/7McsrHVJXsco8l+u\nqgeHw88k2TQ8vwm4OKv5raL3AB9K8hSjW3B/luRL9FzrWeBsVT0y7D/AKPwd1/o+4HRVLVbVr4EH\ngXfTc63jllrfzJq1lkPf+mMWkoTRfdwTVfXpsaeOAHuH7b3AQ6/23FZbVe2vqi1VNc/o7/HbVXU7\nPdd6ATiT5K3DoV2MPr673VoZ3bK5MclVw3/Puxj9rKnjWscttb4jwJ4kVyTZBmwHHn1VZlRVa/YP\n8AHgP4H/Aj4x6/ms8tr+hNE/+f4d+MHw5wPAHzD6Sf6TwL8A18x6rqu87j8FvjZst1wr8EfAwvB3\n+0/AhsZr/Vvgh8ATwD8CV3RaK/AVRj9/+DWjf63dcan1AZ8YenUSeP+rNU9/M1aSmlvLt24kSRMw\n9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jz/wceI2UKyKKmtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5bcba986d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the script into lines: lines\n",
    "lines = holy_grail.split('\\n')\n",
    "\n",
    "# Replace all script lines for speaker\n",
    "pattern = \"[A-Z]{2,}(\\s)?(#\\d)?([A-Z]{2,})?:\"\n",
    "lines = [re.sub(pattern, '', l) for l in lines]\n",
    "\n",
    "# Tokenize each line: tokenized_lines\n",
    "tokenized_lines = [regexp_tokenize(s, r'\\w+') for s in lines]\n",
    "\n",
    "# Make a frequency list of lengths: line_num_words\n",
    "line_num_words = [len(t_line) for t_line in tokenized_lines]\n",
    "\n",
    "# Plot a histogram of the line lengths\n",
    "plt.hist(line_num_words)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Whoa there!  [clop clop clop] ',\n",
       " ' Halt!  Who goes there?',\n",
       " ' It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple topic identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word counts with bag-of-words - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words picker\n",
    "\n",
    "It's time for a quick check on your understanding of bag-of-words. Which of the below options, with basic nltk tokenization, map the bag-of-words for the following text?\n",
    "\n",
    "\"The cat is in the box. The cat box.\"\n",
    "\n",
    "Possible Answers\n",
    "- ('the', 3), ('box.', 2), ('cat', 2), ('is', 1)\n",
    "- ('The', 3), ('box', 2), ('cat', 2), ('is', 1), ('in', 1), ('.', 1)\n",
    "- ('the', 3), ('cat box', 1), ('cat', 1), ('box', 1), ('is', 1), ('in', 1)\n",
    "- ('The', 2), ('box', 2), ('.', 2), ('cat', 2), ('is', 1), ('in', 1), ('the', 1) (Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# article = pd.read_table(\"article.txt\")\n",
    "# article = str(article)\n",
    "\n",
    "with open('article.txt', 'r') as content_file:\n",
    "    article = content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'\\\\\\'\\\\\\'\\\\\\'Debugging\\\\\\'\\\\\\'\\\\\\' is the process of finding and resolving of defects that prevent correct operation of computer software or a system.  \\\\n\\\\nNumerous books have been written about debugging (see below: #Further reading|Further reading), as it involves numerous aspects, including interactive debugging, control flow, integration testing, Logfile|log files, monitoring (Application monitoring|application, System Monitoring|system), memory dumps, Profiling (computer programming)|profiling, Statistical Process Control, and special design tactics to improve detection while simplifying changes.\\\\n\\\\nOrigin\\\\nA computer log entry from the Mark&nbsp;II, with a moth taped to the page\\\\n\\\\nThe terms \"bug\" and \"debugging\" are popularly attributed to Admiral Grace Hopper in the 1940s.[http://foldoc.org/Grace+Hopper Grace Hopper]  from FOLDOC While she was working on a Harvard Mark II|Mark II Computer at Harvard University, her associates discovered a moth stuck in a relay and thereby impeding operation, whereupon she remarked that they were \"debugging\" the system. However the term \"bug\" in the meaning of technical error dates back at least to 1878 and Thomas Edison (see software bug for a full discussion), and \"debugging\" seems to have been used as a term in aeronautics before entering the world of computers. Indeed, in an interview Grace Hopper remarked that she was not coining the term{{Citation needed|date=July 2015}}. The moth fit the already existing terminology, so it was saved.  A letter from J. Robert Oppenheimer (director of the WWII atomic bomb \"Manhattan\" project at Los Alamos, NM) used the term in a letter to Dr. Ernest Lawrence at UC Berkeley, dated October 27, 1944,http://bancroft.berkeley.edu/Exhibits/physics/images/bigscience25.jpg regarding the recruitment of additional technical staff.\\\\n\\\\nThe Oxford English Dictionary entry for \"debug\" quotes the term \"debugging\" used in reference to airplane engine testing in a 1945 article in the Journal of the Royal Aeronautical Society. An article in \"Airforce\" (June 1945 p.&nbsp;50) also refers to debugging, this time of aircraft cameras.  Hopper\\\\\\'s computer bug|bug was found on September 9, 1947. The term was not adopted by computer programmers until the early 1950s.\\\\nThe seminal article by GillS. Gill, [http://www.jstor.org/stable/98663 The Diagnosis of Mistakes in Programmes on the EDSAC], Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, Vol. 206, No. 1087 (May 22, 1951), pp. 538-554 in 1951 is the earliest in-depth discussion of programming errors, but it does not use the term \"bug\" or \"debugging\".\\\\nIn the Association for Computing Machinery|ACM\\\\\\'s digital library, the term \"debugging\" is first used in three papers from 1952 ACM National Meetings.Robert V. D. Campbell, [http://portal.acm.org/citation.cfm?id=609784.609786 Evolution of automatic computation], Proceedings of the 1952 ACM national meeting (Pittsburgh), p 29-32, 1952.Alex Orden, [http://portal.acm.org/citation.cfm?id=609784.609793 Solution of systems of linear inequalities on a digital computer], Proceedings of the 1952 ACM national meeting (Pittsburgh), p. 91-95, 1952.Howard B. Demuth, John B. Jackson, Edmund Klein, N. Metropolis, Walter Orvedahl, James H. Richardson, [http://portal.acm.org/citation.cfm?id=800259.808982 MANIAC], Proceedings of the 1952 ACM national meeting (Toronto), p. 13-16 Two of the three use the term in quotation marks.\\\\nBy 1963 \"debugging\" was a common enough term to be mentioned in passing without explanation on page 1 of the Compatible Time-Sharing System|CTSS manual.[http://www.bitsavers.org/pdf/mit/ctss/CTSS_ProgrammersGuide.pdf The Compatible Time-Sharing System], M.I.T. Press, 1963\\\\n\\\\nKidwell\\\\\\'s article \\\\\\'\\\\\\'Stalking the Elusive Computer Bug\\\\\\'\\\\\\'Peggy Aldrich Kidwell, [http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&arnumber=728224&isnumber=15706 Stalking the Elusive Computer Bug], IEEE Annals of the History of Computing, 1998. discusses the etymology of \"bug\" and \"debug\" in greater detail.\\\\n\\\\nScope\\\\nAs software and electronic systems have become generally more complex, the various common debugging techniques have expanded with more methods to detect anomalies, assess impact, and schedule software patches or full updates to a system. The words \"anomaly\" and \"discrepancy\" can be used, as being more neutral terms, to avoid the words \"error\" and \"defect\" or \"bug\" where there might be an implication that all so-called \\\\\\'\\\\\\'errors\\\\\\'\\\\\\', \\\\\\'\\\\\\'defects\\\\\\'\\\\\\' or \\\\\\'\\\\\\'bugs\\\\\\'\\\\\\' must be fixed (at all costs). Instead, an impact assessment can be made to determine if changes to remove an \\\\\\'\\\\\\'anomaly\\\\\\'\\\\\\' (or \\\\\\'\\\\\\'discrepancy\\\\\\'\\\\\\') would be cost-effective for the system, or perhaps a scheduled new release might render the change(s) unnecessary. Not all issues are life-critical or mission-critical in a system. Also, it is important to avoid the situation where a change might be more upsetting to users, long-term, than living with the known problem(s) (where the \"cure would be worse than the disease\"). Basing decisions of the acceptability of some anomalies can avoid a culture of a \"zero-defects\" mandate, where people might be tempted to deny the existence of problems so that the result would appear as zero \\\\\\'\\\\\\'defects\\\\\\'\\\\\\'. Considering the collateral issues, such as the cost-versus-benefit impact assessment, then broader debugging techniques will expand to determine the frequency of anomalies (how often the same \"bugs\" occur) to help assess their impact to the overall system.\\\\n\\\\nTools\\\\nDebugging on video game consoles is usually done with special hardware such as this Xbox (console)|Xbox debug unit intended for developers.\\\\n\\\\nDebugging ranges in complexity from fixing simple errors to performing lengthy and tiresome tasks of data collection, analysis, and scheduling updates.  The debugging skill of the programmer can be a major factor in the ability to debug a problem, but the difficulty of software debugging varies greatly with the complexity of the system, and also depends, to some extent, on the programming language(s) used and the available tools, such as \\\\\\'\\\\\\'debuggers\\\\\\'\\\\\\'. Debuggers are software tools which enable the programmer to monitor the execution (computers)|execution of a program, stop it, restart it, set breakpoints, and change values in memory. The term \\\\\\'\\\\\\'debugger\\\\\\'\\\\\\' can also refer to the person who is doing the debugging.\\\\n\\\\nGenerally, high-level programming languages, such as Java (programming language)|Java, make debugging easier, because they have features such as exception handling that make real sources of erratic behaviour easier to spot. In programming languages such as C (programming language)|C or assembly language|assembly, bugs may cause silent problems such as memory corruption, and it is often difficult to see where the initial problem happened. In those cases, memory debugging|memory debugger tools may be needed.\\\\n\\\\nIn certain situations, general purpose software tools that are language specific in nature can be very useful.  These take the form of \\\\\\'\\\\\\'List of tools for static code analysis|static code analysis tools\\\\\\'\\\\\\'.  These tools look for a very specific set of known problems, some common and some rare, within the source code.  All such issues detected by these tools would rarely be picked up by a compiler or interpreter, thus they are not syntax checkers, but more semantic checkers.  Some tools claim to be able to detect 300+ unique problems. Both commercial and free tools exist in various languages.  These tools can be extremely useful when checking very large source trees, where it is impractical to do code walkthroughs.  A typical example of a problem detected would be a variable dereference that occurs \\\\\\'\\\\\\'before\\\\\\'\\\\\\' the variable is assigned a value.  Another example would be to perform strong type checking when the language does not require such.  Thus, they are better at locating likely errors, versus actual errors.  As a result, these tools have a reputation of false positives.  The old Unix \\\\\\'\\\\\\'Lint programming tool|lint\\\\\\'\\\\\\' program is an early example.\\\\n\\\\nFor debugging electronic hardware (e.g., computer hardware) as well as low-level software (e.g., BIOSes, device drivers) and firmware, instruments such as oscilloscopes, logic analyzers or in-circuit emulator|in-circuit emulators (ICEs) are often used, alone or in combination.  An ICE may perform many of the typical software debugger\\\\\\'s tasks on low-level software and firmware.\\\\n\\\\nDebugging process \\\\nNormally the first step in debugging is to attempt to reproduce the problem. This can be a non-trivial task, for example as with Parallel computing|parallel processes or some unusual software bugs. Also, specific user environment and usage history can make it difficult to reproduce the problem.\\\\n\\\\nAfter the bug is reproduced, the input of the program may need to be simplified to make it easier to debug. For example, a bug in a compiler can make it Crash (computing)|crash when parsing some large source file. However, after simplification of the test case, only few lines from the original source file can be sufficient to reproduce the same crash. Such simplification can be made manually, using a Divide and conquer algorithm|divide-and-conquer approach. The programmer will try to remove some parts of original test case and check if the problem still exists. When debugging the problem in a Graphical user interface|GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.\\\\n\\\\nAfter the test case is sufficiently simplified, a programmer can use a debugger tool to examine program states (values of variables, plus the call stack) and track down the origin of the problem(s). Alternatively, Tracing (software)|tracing can be used. In simple cases, tracing is just a few print statements, which output the values of variables at certain points of program execution.{{citation needed|date=February 2016}}\\\\n\\\\n Techniques \\\\n \\\\\\'\\\\\\'Interactive debugging\\\\\\'\\\\\\'\\\\n \\\\\\'\\\\\\'{{visible anchor|Print debugging}}\\\\\\'\\\\\\' (or tracing) is the act of watching (live or recorded) trace statements, or print statements, that indicate the flow of execution of a process. This is sometimes called \\\\\\'\\\\\\'{{visible anchor|printf debugging}}\\\\\\'\\\\\\', due to the use of the printf function in C. This kind of debugging was turned on by the command TRON in the original versions of the novice-oriented BASIC programming language. TRON stood for, \"Trace On.\" TRON caused the line numbers of each BASIC command line to print as the program ran.\\\\n \\\\\\'\\\\\\'Remote debugging\\\\\\'\\\\\\' is the process of debugging a program running on a system different from the debugger. To start remote debugging, a debugger connects to a remote system over a network. The debugger can then control the execution of the program on the remote system and retrieve information about its state.\\\\n \\\\\\'\\\\\\'Post-mortem debugging\\\\\\'\\\\\\' is debugging of the program after it has already Crash (computing)|crashed. Related techniques often include various tracing techniques (for example,[http://www.drdobbs.com/tools/185300443 Postmortem Debugging, Stephen Wormuller, Dr. Dobbs Journal, 2006]) and/or analysis of memory dump (or core dump) of the crashed process. The dump of the process could be obtained automatically by the system (for example, when process has terminated due to an unhandled exception), or by a programmer-inserted instruction, or manually by the interactive user.\\\\n \\\\\\'\\\\\\'\"Wolf fence\" algorithm:\\\\\\'\\\\\\' Edward Gauss described this simple but very useful and now famous algorithm in a 1982 article for communications of the ACM as follows: \"There\\\\\\'s one wolf in Alaska; how do you find it? First build a fence down the middle of the state, wait for the wolf to howl, determine which side of the fence it is on. Repeat process on that side only, until you get to the point where you can see the wolf.\"<ref name=\"communications of the ACM\">{{cite journal | title=\"Pracniques: The \"Wolf Fence\" Algorithm for Debugging\", | author=E. J. Gauss | year=1982}} This is implemented e.g. in the Git (software)|Git version control system as the command \\\\\\'\\\\\\'git bisect\\\\\\'\\\\\\', which uses the above algorithm to determine which Commit (data management)|commit introduced a particular bug.\\\\n \\\\\\'\\\\\\'Delta Debugging\\\\\\'\\\\\\'{{snd}} a technique of automating test case simplification.Andreas Zeller: <cite>Why Programs Fail: A Guide to Systematic Debugging</cite>, Morgan Kaufmann, 2005. ISBN 1-55860-866-4{{rp|p.123}}<!-- for redirect from \\\\\\'Saff Squeeze\\\\\\' -->\\\\n \\\\\\'\\\\\\'Saff Squeeze\\\\\\'\\\\\\'{{snd}} a technique of isolating failure within the test using progressive inlining of parts of the failing test.[http://www.threeriversinstitute.org/HitEmHighHitEmLow.html Kent Beck, Hit \\\\\\'em High, Hit \\\\\\'em Low: Regression Testing and the Saff Squeeze]\\\\n\\\\nDebugging for embedded systems\\\\nIn contrast to the general purpose computer software design environment, a primary characteristic of embedded environments is the sheer number of different platforms available to the developers (CPU architectures, vendors, operating systems and their variants). Embedded systems are, by definition, not general-purpose designs: they are typically developed for a single task (or small range of tasks), and the platform is chosen specifically to optimize that application. Not only does this fact make life tough for embedded system developers, it also makes debugging and testing of these systems harder as well, since different debugging tools are needed in different platforms.\\\\n\\\\nto identify and fix bugs in the system (e.g. logical or synchronization problems in the code, or a design error in the hardware);\\\\nto collect information about the operating states of the system that may then be used to analyze the system: to find ways to boost its performance or to optimize other important characteristics (e.g. energy consumption, reliability, real-time response etc.).\\\\n\\\\nAnti-debugging\\\\nAnti-debugging is \"the implementation of one or more techniques within computer code that hinders attempts at reverse engineering or debugging a target process\".<ref name=\"veracode-antidebugging\">{{cite web |url=http://www.veracode.com/blog/2008/12/anti-debugging-series-part-i/ |title=Anti-Debugging Series - Part I |last=Shields |first=Tyler |date=2008-12-02 |work=Veracode |accessdate=2009-03-17}} It is actively used by recognized publishers in copy protection|copy-protection schemas, but is also used by malware to complicate its detection and elimination.<ref name=\"soft-prot\">[http://people.seas.harvard.edu/~mgagnon/software_protection_through_anti_debugging.pdf Software Protection through Anti-Debugging Michael N Gagnon, Stephen Taylor, Anup Ghosh] Techniques used in anti-debugging include:\\\\nAPI-based: check for the existence of a debugger using system information\\\\nException-based: check to see if exceptions are interfered with\\\\nProcess and thread blocks: check whether process and thread blocks have been manipulated\\\\nModified code: check for code modifications made by a debugger handling software breakpoints\\\\nHardware- and register-based: check for hardware breakpoints and CPU registers\\\\nTiming and latency: check the time taken for the execution of instructions\\\\nDetecting and penalizing debugger<ref name=\"soft-prot\" /><!-- reference does not exist -->\\\\n\\\\nAn early example of anti-debugging existed in early versions of Microsoft Word which, if a debugger was detected, produced a message that said: \"The tree of evil bears bitter fruit. Now trashing program disk.\", after which it caused the floppy disk drive to emit alarming noises with the intent of scaring the user away from attempting it again.<ref name=\"SecurityEngineeringRA\">{{cite book | url=http://www.cl.cam.ac.uk/~rja14/book.html | author=Ross J. Anderson | title=Security Engineering | isbn = 0-471-38922-6 | page=684 }}<ref name=\"toastytech\">{{cite web | url=http://toastytech.com/guis/word1153.html | title=Microsoft Word for DOS 1.15}}\\\\n\\''"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Counter with bag-of-words\n",
    "\n",
    "In this exercise, you'll build your first (in this course) bag-of-words counter using a Wikipedia article, which has been pre-loaded as article. Try doing the bag-of-words without looking at the full article text, and guessing what the topic is! If you'd like to peek at the title at the end, we've included it as article_title. Note that this article text has had very little preprocessing from the raw Wikipedia database entry.\n",
    "\n",
    "word_tokenize has been imported for you.\n",
    "\n",
    "Instructions\n",
    "- Import Counter from collections.\n",
    "- Use word_tokenize() to split the article into tokens.\n",
    "- Use a list comprehension with t as the iterator variable to convert all the tokens into lowercase. The .lower() method converts text into lowercase.\n",
    "- Create a bag-of-words counter called bow_simple by using Counter() with lower_tokens as the argument.\n",
    "- Use the .most_common() method of bow_simple to print the 10 most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 151), ('the', 147), ('of', 81), ('.', 70), ('to', 61), ('a', 59), (\"''\", 42), ('and', 41), ('in', 41), ('(', 40)]\n"
     ]
    }
   ],
   "source": [
    "# Import Counter\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize the article: tokens\n",
    "tokens = word_tokenize(article)\n",
    "\n",
    "# Convert the tokens into lowercase: lower_tokens\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "\n",
    "# Create a Counter with the lowercase tokens: bow_simple\n",
    "bow_simple = Counter(lower_tokens)\n",
    "\n",
    "# Print the 10 most common tokens\n",
    "print(bow_simple.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple text preprocessing - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing steps\n",
    "\n",
    "Which of the following are useful text preprocessing steps?\n",
    "\n",
    "Possible Answers\n",
    "- Stems, spelling corrections, lowercase.\n",
    "- Lemmatization, lowercasing, removing unwanted tokens. (Correct)\n",
    "- Removing stop words, leaving in capital words.\n",
    "- Strip stop words, word endings and digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing practice\n",
    "\n",
    "Now, it's your turn to apply the techniques you've learned to help clean up text for better NLP results. You'll need to remove stop words and non-alphabetic characters, lemmatize, and perform a new bag-of-words on your cleaned text.\n",
    "\n",
    "You start with the same tokens you created in the last exercise: lower_tokens. You also have the Counter class imported.\n",
    "\n",
    "Instructions\n",
    "- Import the WordNetLemmatizer class from nltk.stem.\n",
    "- Create a list called alpha_only that iterates through lower_tokens and retains only alphabetical characters. You can use the .isalpha() method to check for this.\n",
    "- Create another list called no_stops in which you remove all stop words, which are held in a list called english_stops.\n",
    "- Initialize a WordNetLemmatizer object called wordnet_lemmatizer and use its .lemmatize() method on the tokens in no_stops to create a new list called lemmatized.\n",
    "- Finally, create a new Counter called bow with the lemmatized words and show the 10 most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# english_stops = pd.read_table(\"english_stopwords.txt\")\n",
    "# #english_stops\n",
    "# english_stops = str(english_stops)\n",
    "#Read the file english_stopwords.txt\n",
    "with open('english_stopwords.txt', 'r') as content_file:\n",
    "    english_stops = content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(english_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('debugging', 30), ('system', 23), ('software', 16), ('computer', 14), ('bug', 14), ('problem', 14), ('term', 13), ('tool', 13), ('process', 12), ('used', 12)]\n"
     ]
    }
   ],
   "source": [
    "# Import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Retain alphabetic words: alpha_only\n",
    "alpha_only = [t for t in lower_tokens if t.isalpha()]\n",
    "\n",
    "# Remove all stop words: no_stops\n",
    "no_stops = [t for t in alpha_only if t not in english_stops]\n",
    "\n",
    "# Instantiate the WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize all tokens into a new list: lemmatized\n",
    "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
    "\n",
    "# Create the bag-of-words: bow\n",
    "bow = Counter(lemmatized)\n",
    "\n",
    "# Print the 10 most common tokens\n",
    "print(bow.most_common(10))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retain alphabetic words: alpha_only\n",
    "alpha_only = [t for t in lower_tokens if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove all stop words: no_stops\n",
    "no_stops = [t for t in alpha_only if t not in english_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 8, 10]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2,4,6,8,10,12]\n",
    "y = [3,6,9,12]\n",
    "z = [t for t in x if t not in y]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two', 'four', 'eight', 'ten']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"two\", \"four\", \"six\", \"eight\", \"ten\", \"twelve\"]\n",
    "y = [\"three\",\"six\", \"nine\", \"twelve\"]\n",
    "[t for t in x if t not in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to gensim - Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 12,\n",
       " ',': 16,\n",
       " '.': 8,\n",
       " 'a': 4,\n",
       " 'about': 3,\n",
       " 'action': 14,\n",
       " 'alien': 22,\n",
       " 'aliens': 7,\n",
       " 'and': 6,\n",
       " 'awesome': 13,\n",
       " 'awful': 20,\n",
       " 'boring': 18,\n",
       " 'but': 17,\n",
       " 'characters': 19,\n",
       " 'cool': 26,\n",
       " 'films': 23,\n",
       " 'hate': 21,\n",
       " 'i': 9,\n",
       " 'is': 25,\n",
       " 'liked': 11,\n",
       " 'more': 27,\n",
       " 'movie': 1,\n",
       " 'please': 28,\n",
       " 'really': 10,\n",
       " 'scenes': 15,\n",
       " 'space': 24,\n",
       " 'spaceship': 5,\n",
       " 'the': 0,\n",
       " 'was': 2}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_documents = ['The movie was about a spaceship and aliens.',\n",
    "'I really liked the movie!',\n",
    "'Awesome action scenes, but boring characters.',\n",
    "'The movie was awful! I hate alien films.',\n",
    "'Space is cool! I liked the movie.',\n",
    "'More space films, please!',]\n",
    "\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in my_documents]\n",
    "# tokenized_docs\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "#ictionary\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(8, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)],\n",
       " [(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (12, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1)],\n",
       " [(0, 1), (1, 1), (8, 1), (9, 1), (11, 1), (12, 1), (24, 1), (25, 1), (26, 1)],\n",
       " [(12, 1), (16, 1), (23, 1), (24, 1), (27, 1), (28, 1)]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are word vectors?\n",
    "\n",
    "What are word vectors and how do they help with NLP?\n",
    "\n",
    "Possible Answers\n",
    "Click or Press Ctrl+1 to focus\n",
    " - They are similar to bags of words, just with numbers. You use them to count how many tokens there are.\n",
    " - Word vectors are sparse arrays representing bigrams in the corpora. You can use them to compare two sets of words to one another.\n",
    " - Word vectors are multi-dimensional mathematical representations of words created using deep learning methods. They give us insight into relationships between words in a corpus. (Correct)\n",
    " - Word vectors don't actually help NLP and are just hype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and querying a corpus with gensim\n",
    "\n",
    "It's time to apply the methods you learned in the previous video to create your first gensim dictionary and corpus!\n",
    "\n",
    "You'll use these data structures to investigate word trends and potential interesting topics in your document set. To get started, we have imported a few additional messy articles from Wikipedia, which were preprocessed by lowercasing all words, tokenizing them, and removing stop words and punctuation. These were then stored in a list of document tokens called articles. You'll need to do some light preprocessing and then generate the gensim dictionary and corpus.\n",
    "\n",
    "Instructions\n",
    "- Import Dictionary from gensim.corpora.dictionary.\n",
    "- Initialize a gensim Dictionary with the tokens in articles.\n",
    "- Obtain the id for \"computer\" from dictionary. To do this, use its .token2id method which returns ids from text, and then chain .get() which returns tokens from ids. Pass in \"computer\" as an argument to .get().\n",
    "- Use a list comprehension in which you iterate over articles to create a gensim MmCorpus from dictionary.\n",
    "- In the output expression, use the .doc2bow() method on dictionary with article as the argument.\n",
    "- Print the first 10 word ids with their frequency counts from the fifth document. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Code - to extract data from txt files in Wikipedia articles folder\n",
    "import glob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = 'Wikipedia articles/wiki_text*.txt'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "txt_files = glob.glob(pattern)\n",
    "txt_files\n",
    "\n",
    "read_files = []\n",
    "for txt in txt_files:\n",
    "\n",
    "    with open(txt, 'r', encoding=\"utf8\") as content_file:\n",
    "        read_files.append(content_file.read())\n",
    "\n",
    "articles = []\n",
    "for files in read_files:\n",
    "    tokens = [w for w in word_tokenize(files.lower()) if w.isalpha()]\n",
    "    no_stops = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    articles.append(no_stops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'disambiguation',\n",
       " 'computer',\n",
       " 'div',\n",
       " 'nowrap',\n",
       " 'file',\n",
       " 'acer',\n",
       " 'aspire',\n",
       " 'gemstone',\n",
       " 'columbia',\n",
       " 'supercomputer',\n",
       " 'nasa',\n",
       " 'advanced',\n",
       " 'supercomputing',\n",
       " 'intertec',\n",
       " 'br',\n",
       " 'thinking',\n",
       " 'machines',\n",
       " 'connection',\n",
       " 'machine',\n",
       " 'frostburg',\n",
       " 'supplying',\n",
       " 'wikipedia',\n",
       " 'via',\n",
       " 'gigabit',\n",
       " 'lange',\n",
       " 'nacht',\n",
       " 'der',\n",
       " 'wissenschaften']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 words in the first document list in articles list\n",
    "articles[1][1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer\n",
      "[(2, 3), (4, 5), (5, 11), (7, 4), (9, 16), (11, 12), (13, 1), (16, 12), (17, 10), (22, 2)]\n"
     ]
    }
   ],
   "source": [
    "# Import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a Dictionary from the articles: dictionary\n",
    "dictionary = Dictionary(articles)\n",
    "\n",
    "# Select the id for \"computer\": computer_id\n",
    "computer_id = dictionary.token2id.get(\"computer\")\n",
    "\n",
    "# Use computer_id with the dictionary to print the word\n",
    "print(dictionary.get(computer_id))\n",
    "\n",
    "# Create a MmCorpus: corpus\n",
    "corpus = [dictionary.doc2bow(article) for article in articles]\n",
    "\n",
    "# Print the first 10 word ids with their frequency counts from the fifth document\n",
    "print(corpus[4][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim bag-of-words\n",
    "\n",
    "Now, you'll use your new gensim corpus and dictionary to see the most common terms per document and across all documents. You can use your dictionary to look up the terms. Take a guess at what the topics are and feel free to explore more documents in the IPython Shell!\n",
    "\n",
    "You have access to the dictionary and corpus objects you created in the previous exercise, as well as the Python defaultdict and itertools to help with the creation of intermediate data structures for analysis.\n",
    "\n",
    "The fifth document from corpus is stored in the variable doc, which has been sorted in descending order.\n",
    "\n",
    "Instructions\n",
    "- Print the top five words of bow_doc using each word_id with the dictionary alongside word_count. The word_id can be accessed using the .get() method of dictionary.\n",
    "- Create a defaultdict called total_word_count in which the keys are all the token ids (word_id) and the values are the sum of their occurrence across all documents (word_count). Remember to specify int when creating the defaultdict, and inside the for loop, increment each word_id of total_word_count by word_count.\n",
    "- Create a sorted list from the defaultdict, using words across the entire corpus. To achieve this, use the .items() method on total_word_count inside sorted().\n",
    "- Similar to how you printed the top five words of bow_doc earlier, print the top five words of sorted_word_count as well as the number of occurrences of each word across all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debugging 40\n",
      "system 19\n",
      "software 16\n",
      "tools 14\n",
      "process 12\n",
      "computer 594\n",
      "software 450\n",
      "cite 322\n",
      "ref 259\n",
      "code 234\n"
     ]
    }
   ],
   "source": [
    "# Save the fifth document: doc\n",
    "doc = corpus[4]\n",
    "\n",
    "# Sort the doc for frequency: bow_doc\n",
    "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 5 words of the document alongside the count\n",
    "for word_id, word_count in bow_doc[:5]:\n",
    "     #print(word_id, word_count)\n",
    "    print(dictionary.get(word_id), word_count)\n",
    "    \n",
    "# Create the defaultdict: total_word_count\n",
    "total_word_count = defaultdict(int)\n",
    "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "    total_word_count[word_id] += word_count\n",
    "\n",
    "# Create a sorted list from the defaultdict: sorted_word_count\n",
    "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True) \n",
    "\n",
    "# Print the top 5 words across all documents alongside the count\n",
    "for word_id, word_count in sorted_word_count[:5]:\n",
    "    print(dictionary.get(word_id), word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf with gensim - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is tf-idf?\n",
    "\n",
    "\n",
    "You want to calculate the tf-idf weight for the word \"computer\", which appears five times in a document containing 100 words. Given a corpus containing 200 documents, with 20 documents mentioning the word \"computer\", tf-idf can be calculated by multiplying term frequency with inverse document frequency.\n",
    "\n",
    "Term frequency = percentage share of the word compared to all tokens in the document Inverse document frequency = logarithm of the total number of documents in a corpora divided by the number of documents containing the term\n",
    "\n",
    "Which of the below options is correct?\n",
    "Possible Answers\n",
    "\n",
    " - (5 / 100) * log(200 / 20) (Correct)\n",
    " - (5 * 100) / log(200 * 20)\n",
    " - (20 / 5) * log(200 / 20)\n",
    " - (200 * 5) * log(400 / 5)\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf with Wikipedia\n",
    "\n",
    "\n",
    "Now it's your turn to determine new significant terms for your corpus by applying gensim's tf-idf. You will again have access to the same corpus and dictionary objects you created in the previous exercises - dictionary, corpus, and doc. Will tf-idf make for more interesting results on the document level?\n",
    "Instructions\n",
    "\n",
    " - Import TfidfModel from gensim.models.tfidfmodel.\n",
    " - Initialize a new TfidfModel called tfidf using corpus.\n",
    " - Use doc to calculate the weights. You can do this by passing [doc] to tfidf.\n",
    " - Print the first five term ids with weights.\n",
    " - Sort the term ids and weights in a new list from highest to lowest weight. This has been done for you.\n",
    " - Print the top five weighted words (term_id) from sorted_tfidf_weights along with their weighted score (weight).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.022197157026523636), (4, 0.007939052212344833), (5, 0.057746823002805925), (11, 0.03992471997759224), (13, 0.02004781586642236)]\n",
      "wolf 0.22672671457458993\n",
      "debugging 0.20998844728293067\n",
      "fence 0.18138137165967194\n",
      "tron 0.13603602874475396\n",
      "squeeze 0.13603602874475396\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfModel\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "# Create a new TfidfModel using the corpus: tfidf\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "# Calculate the tfidf weights of doc: tfidf_weights\n",
    "tfidf_weights = tfidf[doc]\n",
    "\n",
    "# Print the first five weights\n",
    "print(tfidf_weights[0:5])\n",
    "\n",
    "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
    "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 5 weighted words\n",
    "for term_id, weight in sorted_tfidf_weights[:5]:\n",
    "    print(dictionary.get(term_id), weight)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Datacamp Output\n",
    "<script.py> output:\n",
    "    [(0, 0.023420126880188786), (1, 0.005482438072568852), (7, 0.005078279214193905), (13, 0.0011417502439189165), (21, 0.017362751314599745)]\n",
    "    reverse 0.4884677479380291\n",
    "    infringement 0.18673443711656115\n",
    "    engineering 0.1639408881613215\n",
    "    interoperability 0.1244896247443741\n",
    "    reverse-engineered 0.1244896247443741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter will introduce a slightly more advanced topic - Named-entity recognition. You'll learn how to identify the who, what and where of your texts using pre-trained models on English and non-English text. You'll also learn how to use some new libraries - polyglot and spaCy - to add to your NLP toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER with NLTK\n",
    "\n",
    "You're now going to have some fun with named-entity recognition! A scraped news article has been pre-loaded into your workspace. Your task is to use nltk to find the named entities in this article.\n",
    "\n",
    "What might the article be about, given the names you found?\n",
    "\n",
    "Along with nltk, sent_tokenize and word_tokenize from nltk.tokenize have been pre-imported.\n",
    "Instructions\n",
    "\n",
    "  - Tokenize article into sentences.\n",
    "  - Tokenize each sentence in sentences into words using a list comprehension.\n",
    "  - Inside a list comprehension, tag each tokenized sentence into parts of speech using nltk.pos_tag().\n",
    "  - Chunk each tagged sentence into named-entity chunks using nltk.ne_chunk_sents(). Along with pos_sentences, specify the additional keyword argument binary=True.\n",
    "  - Loop over each sentence and each chunk, and test whether it is a named-entity chunk by testing if it has the attribute label, and if the chunk.label() is equal to \"NE\". If so, print that chunk.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#HINT\n",
    "Hint\n",
    "\n",
    "    Use nltk.sent_tokenize() to tokenize article into sentences.\n",
    "    Use nltk.word_tokenize() with sent as the argument as the output expression of your list comprehension to tokenize each sentence into words.\n",
    "    Similar to how you created token_sentences, use nltk.pos_tag() to create pos_sentences.\n",
    "    To chunk each tagged sentence into named-entity chunks, use the nltk.ne_chunk_sents() function with two arguments: the parts of speech tagged sentences, as well as binary=True.\n",
    "    Inside the nested for loop, check whether chunk.label() equals \"NE\". If it does, print that chunk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Solution is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the article into sentences: sentences\n",
    "sentences = nltk.sent_tokenize(article)\n",
    "\n",
    "# Tokenize each sentence into words: token_sentences\n",
    "token_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# Tag each tokenized sentence into parts of speech: pos_sentences\n",
    "pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences] \n",
    "\n",
    "# Create the named entity chunks: chunked_sentences\n",
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=True)\n",
    "\n",
    "# Test for stems of the tree with 'NE' tags\n",
    "for sent in chunked_sentences:\n",
    "    for chunk in sent:\n",
    "        if hasattr(chunk, \"label\") and chunk.label() == \"NE\":\n",
    "            print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `nltk.ne_chunk_sents` not found.\n"
     ]
    }
   ],
   "source": [
    "?nltk.ne_chunk_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charting practice\n",
    "\n",
    "In this exercise, you'll use some extracted named entities and their groupings from a series of newspaper articles to chart the diversity of named entity types in the articles.\n",
    "\n",
    "You'll use a defaultdict called ner_categories, with keys representing every named entity group type, and values to count the number of each different named entity type. You have a chunked sentence list called chunked_sentences similar to the last exercise, but this time with non-binary category names.\n",
    "\n",
    "You can use hasattr() to determine if each chunk has a 'label' and then simply use the chunk's .label() method as the dictionary key.\n",
    "Instructions\n",
    "\n",
    "  - Create a defaultdict called ner_categories, with the default type set to int.\n",
    "  - Fill up the dictionary with values for each of the keys. Remember, the keys will represent the label().\n",
    "      - In the outer for loop, iterate over chunked_sentences, using sent as your iterator variable.\n",
    "      - In the inner for loop, iterate over sent. If the condition is true, increment the value of each key by 1.\n",
    "  - For the pie chart labels, create a list called labels from the keys of ner_categories, which can be accessed using .keys().\n",
    "  - Use a list comprehension to create a list called values, using the .get() method on ner_categories to compute the values of each label l.\n",
    "  - Use plt.pie() to create a pie chart for each of the NER categories. Along with values and labels=labels, pass the extra keyword arguments autopct='%1.1f%%' and startangle=140 to add percentages to the chart and rotate the initial start angle.\n",
    "  - Display your pie chart. Was the distribution what you expected?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hint\n",
    "\n",
    "    Use defaultdict(int) to create ner_categories.\n",
    "    If the condition inside the nested for loop is true, increment ner_categories[chunk.label()].\n",
    "    Use the .keys() method on ner_categories to access its keys.\n",
    "    Use the .get() method on ner_categories with l as the argument to compute the values.\n",
    "    Use plt.pie() with the arguments specified in the instructions to create the pie chart. Then, use plt.show() to display it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the defaultdict: ner_categories\n",
    "ner_categories = defaultdict(int)\n",
    "\n",
    "# Create the nested for loop\n",
    "for sent in chunked_sentences:\n",
    "    for chunk in sent:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            ner_categories[chunk.label()] += 1\n",
    "            \n",
    "# Create a list from the dictionary keys for the chart labels: labels\n",
    "labels = list(ner_categories.keys())\n",
    "\n",
    "# Create a list of the values: values\n",
    "values = [ner_categories.get(l) for l in labels]\n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford library with NLTK\n",
    "\n",
    "\n",
    "When using the Stanford library with NLTK, what is needed to get started?\n",
    "Possible Answers\n",
    "\n",
    "    - A normal installation of NLTK.\n",
    "    - An installation of the Stanford Java Library.\n",
    "    - Both NLTK and an installation of the Stanford Java Library.\n",
    "    - NLTK, the Standford Java Libraries and some environment variables to help with integration. (Correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing NLTK with spaCy NER\n",
    "\n",
    "\n",
    "Using the same text you used in the first exercise of this chapter, you'll now see the results using spaCy's NER annotator. How will they compare?\n",
    "\n",
    "The article has been pre-loaded as article. To minimize execution times, you'll be asked to specify the keyword arguments tagger=False, parser=False, matcher=False when loading the spaCy model, because you only care about the entity in this exercise.\n",
    "Instructions\n",
    "\n",
    "   - Import spacy.\n",
    "   - Load the 'en' model using spacy.load(). Specify the additional keyword arguments tagger=False, parser=False, matcher=False.\n",
    "   - Create a spacy document object by passing article into nlp().\n",
    "   - Using ent as your iterator variable, iterate over the entities of doc and print out the labels (ent.label_) and text (ent.text).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint\n",
    "\n",
    "    Use the import keyword to import the module of interest.\n",
    "    Pass in 'en' to spacy.load(), along with the other keyword arguments specified in the instructions.\n",
    "    Use nlp(article) to create doc.\n",
    "    Iterate over doc.ents, printing the .label_ and .text attributes (in that order) of ent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# Instantiate the English model: nlp\n",
    "nlp = spacy.load('en', tagger=False, parser=False, matcher=False)\n",
    "\n",
    "# Create a new document: doc\n",
    "doc = nlp(article)\n",
    "\n",
    "# Print all of the found entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy NER Categories\n",
    "\n",
    "Which are the extra categories that spacy uses compared to nltk in its named-entity recognition?\n",
    "Possible Answers\n",
    "\n",
    "    - GPE, PERSON, MONEY\n",
    "    - ORGANIZATION, WORKOFART\n",
    "    - NORP, CARDINAL, MONEY, WORKOFART, LANGUAGE, EVENT (Correct)\n",
    "    - EVENT_LOCATION, FIGURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual NER with polyglot - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French NER with polyglot I\n",
    "\n",
    "\n",
    "In this exercise and the next, you'll use the polyglot library to identify French entities. The library functions slightly differently than spacy, so you'll use a few of the new things you learned in the last video to display the named entity text and category.\n",
    "\n",
    "You have access to the full article string in article. Additionally, the Text class of polyglot has been imported from polyglot.text.\n",
    "Instructions\n",
    "\n",
    "     - Create a new Text object called txt.\n",
    "     - Iterate over txt.entities and print each entity, ent.\n",
    "     - Print the type of each entity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new text object using Polyglot's Text class: txt\n",
    "txt = Text(article)\n",
    "\n",
    "# Print each of the entities found\n",
    "for ent in txt.entities:\n",
    "    print(ent)\n",
    "    \n",
    "# Print the type of each entity\n",
    "print(type(ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French NER with polyglot II\n",
    "\n",
    "Here, you'll complete the work you began in the previous exercise. Your code from there has already been executed, as you can see from the output in the IPython Shell.\n",
    "\n",
    "Your task is to use a list comprehension to create a list of tuples, in which the first element is the entity tag, and the second element is the full string of the entity text.\n",
    "Instructions\n",
    "\n",
    "   - Use a list comprehension to create a list of tuples called entities.\n",
    "       - The output expression of your list comprehension should be a tuple. Remember to use () to create the tuple.\n",
    "          -  The first element of each tuple is the entity tag, which you can access using its .tag attribute.\n",
    "           - The second element is the full string of the entity text, which you can access using ' '.join(ent).\n",
    "       - Your iterator variable should be ent, and you should iterate over all of the entities of the polyglot Text object, txt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the list of tuples: entities\n",
    "entities = [(ent.tag, ' '.join(ent)) for ent in txt.entities]\n",
    "\n",
    "# Print the entities\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish NER with polyglot\n",
    "\n",
    "\n",
    "You'll continue your exploration of polyglot now with some Spanish annotation. This article is not written by a newspaper, so it is your first example of a more blog-like text. How do you think that might compare when finding entities?\n",
    "\n",
    "The Text object has been created as txt, and each entity has been printed, as you can see in the IPython Shell.\n",
    "\n",
    "Your specific task is to determine how many of the entities contain the words \"Márquez\" or \"Gabo\" - these refer to the same person in different ways!\n",
    "Instructions\n",
    "\n",
    "    - Iterate over all of the entities of txt, using ent as your iterator variable.\n",
    "    - Check whether the entity contains \"Márquez\" or \"Gabo\". If it does, increment count.\n",
    "    - Hit 'Submit Answer' to see what percentage of entities refer to Gabriel García Márquez (aka Gabo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"alex\" in [\"alex\", \"martin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the count variable: count\n",
    "count = 0\n",
    "\n",
    "# Iterate over all the entities\n",
    "for ent in txt.entities:\n",
    "    # Check whether the entity contains 'Márquez' or 'Gabo'\n",
    "    if \"Márquez\" in ent or \"Gabo\" in ent:\n",
    "        # Increment count\n",
    "        count += 1\n",
    "\n",
    "# Print count\n",
    "print(count)\n",
    "\n",
    "# Calculate the percentage of entities that refer to \"Gabo\": percentage\n",
    "percentage = count * 1.0 / len(txt.entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER via ensemble model\n",
    "\n",
    "\n",
    "In the final exercise of this NER chapter, you'll use the spacy and polyglot models to extract the best entities possible from English text. Here, you'll be using a long Medium post with a mixture of more formal article writing and informal. You'll find entities using both spacy and polyglot and choose only entities identified by both to create a sort of ensemble model.\n",
    "\n",
    "In this exercise, you have access to the polyglot Text class and the loaded english vectors for spacy in nlp. You also have the article text in article. The set of polyglot entities have been computed and are available in poly_ents. Your task is to compute the spacy entities and then find the intersection between the polyglot entities and the spacy entities.\n",
    "\n",
    "Here, you'll be working with sets. A set comprehension looks exactly like a list comprehension, with the exception that it uses the set syntax markers {}.\n",
    "Instructions\n",
    "\n",
    "     - Use a set comprehension to create a set of spacy entities, keeping only the text. The document object is available as doc. The text can be accessed using the .text attribute of each entity.\n",
    "     - Use the set method .intersection() to find the entities that are in both spacy_ents and poly_ents.\n",
    "     - Calculate the number of entities not included in the new ensemble set of entities. You can do this by calculating the length of the union of spacy_ents and poly_ents (which can be computed using the .union() method) and then subtracting the length of ensemble_ents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint\n",
    "\n",
    "    The output expression of your set comprehension should be e.text. You can iterate over all the entities in doc using doc.ents.\n",
    "    Use the .intersection() method on spacy_ents with poly_ents as the argument to find the common entities.\n",
    "    To calculate num_left_out, first calculate the union of spacy_ents and poly_ents, using the .union() method. Then calculate its length using len(), and subtract the length of ensemble_ents from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of spaCy entities keeping only their text: spacy_ents\n",
    "spacy_ents = {e.text for e in doc.ents} \n",
    "\n",
    "# Create a set of the intersection between the spacy and polyglot entities: ensemble_ents\n",
    "ensemble_ents = spacy_ents.intersection(poly_ents)\n",
    "\n",
    "# Print the common entities\n",
    "print(ensemble_ents)\n",
    "\n",
    "# Calculate the number of entities not included in the new ensemble set of entities: num_left_out\n",
    "num_left_out = len(spacy_ents.union(poly_ents)) - len(ensemble_ents)\n",
    "print(num_left_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which possible features?\n",
    "\n",
    "\n",
    "Which of the following are possible features for a text classification problem?\n",
    "Possible Answers\n",
    "\n",
    "    Number of words in a document.\n",
    "    1\n",
    "    Specific named entities.\n",
    "    2\n",
    "    Language.\n",
    "    3\n",
    "    All of the above. (Correct)\n",
    "    4\n",
    "\n",
    "    Take Hint (-15xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing\n",
    "\n",
    "\n",
    "What datasets are needed for supervised learning?\n",
    "Possible Answers\n",
    "\n",
    "    Training data.\n",
    "    1\n",
    "    Testing data.\n",
    "    2\n",
    "    Both training and testing data. (Correct)\n",
    "    3\n",
    "    A label or outcome.\n",
    "    4\n",
    "\n",
    "    Take Hint (-15xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building word count vectors with scikit-learn - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer for text classification\n",
    "\n",
    "It's time to begin building your text classifier! The data has been loaded into a DataFrame called df. Explore it in the IPython Shell to investigate what columns you can use. The .head() method is particularly informative.\n",
    "\n",
    "In this exercise, you'll use pandas alongside scikit-learn to create a sparse text vectorizer you can use to train and test a simple supervised model. To begin, you'll set up a CountVectorizer and investigate some of its features.\n",
    "Instructions\n",
    "\n",
    "    - Import CountVectorizer from sklearn.feature_extraction.text and train_test_split from sklearn.model_selection.\n",
    "    - Create a Series y to use for the labels by assigning the .label attribute of df to y.\n",
    "    - Using df[\"text\"] (features) and y (labels), create training and test sets using train_test_split(). Use a test_size of 0.33 and a random_state of 53.\n",
    "    - Create a CountVectorizer object called count_vectorizer. Ensure you specify the keyword argument stop_words=\"english\" so that stop words are removed.\n",
    "    - Fit and transform the training data X_train using the .fit_transform() method. Do the same with the test data X_test, except using the .transform() method.\n",
    "    - Print the first 10 features of the count_vectorizer using its .get_feature_names() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], \n",
    "                                                      y, \n",
    "                                                      test_size=0.33,\n",
    "                                                      random_state = 53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer for text classification\n",
    "\n",
    "Similar to the sparse CountVectorizer created in the previous exercise, you'll work on creating tf-idf vectors for your documents. You'll set up a TfidfVectorizer and investigate some of its features.\n",
    "\n",
    "In this exercise, you'll use pandas and sklearn along with the same X_train, y_train and X_test, y_test DataFrames and Series you created in the last exercise.\n",
    "Instructions\n",
    "\n",
    "     - Import TfidfVectorizer from sklearn.feature_extraction.text.\n",
    "     - Create a TfidfVectorizer object called tfidf_vectorizer. When doing so, specify the keyword arguments stop_words=\"english\" and max_df=0.7.\n",
    "     - Fit and transform the training data.\n",
    "     - Transform the test data.\n",
    "     - Print the first 10 features of tfidf_vectorizer.\n",
    "     - Print the first 5 vectors of the tfidf training data using slicing on the .A (or array) attribute of tfidf_train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the vectors\n",
    "\n",
    "\n",
    "To get a better idea of how the vectors work, you'll investigate them by converting them into pandas DataFrames.\n",
    "\n",
    "Here, you'll use the same data structures you created in the previous two exercises (count_train, count_vectorizer, tfidf_train, tfidf_vectorizer) as well as pandas, which is imported as pd.\n",
    "Instructions\n",
    "\n",
    "     - Create the DataFrames count_df and tfidf_df by using pd.DataFrame() and specifying the values as the first argument and the columns (or features) as the second argument.\n",
    "         - The values can be accessed by using the .A attribute of, respectively, count_train and tfidf_train.\n",
    "         - The columns can be accessed using the .get_feature_names() methods of count_vectorizer and tfidf_vectorizer.\n",
    "     - Print the head of each DataFrame to investigate their structure.\n",
    "     - Test if the column names are the same for each DataFrame by creating a new object called difference to see the difference between the columns that count_df has from tfidf_df. Columns can be accessed using the .columns attribute of a DataFrame. Subtract the set of tfidf_df.columns from the set of count_df.columns.\n",
    "     - Test if the two DataFrames are equivalent by using the .equals() method on count_df with tfidf_df as the argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of count_df\n",
    "print(count_df.head())\n",
    "\n",
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a classification model with scikit-learn - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification models\n",
    "\n",
    "Which of the below is the most reasonable model to use when training a new supervised model using text vector data?\n",
    "Possible Answers\n",
    "\n",
    "    Random Forests\n",
    "    1\n",
    "    Naive Bayes (Correct)\n",
    "    2\n",
    "    Linear Regression\n",
    "    3\n",
    "    Deep Learning\n",
    "    4\n",
    "\n",
    "    Take Hint (-15xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the \"fake news\" model with CountVectorizer\n",
    "\n",
    "\n",
    "Now it's your turn to train the \"fake news\" model using the features you identified and extracted. In this first exercise you'll train and test a Naive Bayes model using the CountVectorizer data.\n",
    "\n",
    "The training and test sets have been created, and count_vectorizer, count_train, and count_test have been computed.\n",
    "Instructions\n",
    "\n",
    "   - Import the metrics module from sklearn and MultinomialNB from sklearn.naive_bayes.\n",
    "   - Instantiate a MultinomialNB classifier called nb_classifier.\n",
    "   - Fit the classifier to the training data.\n",
    "   - Compute the predicted tags for the test data.\n",
    "   - Calculate and print the accuracy score of the classifier.\n",
    "   - Compute the confusion matrix. To make it easier to read, specify the keyword argument labels=['FAKE', 'REAL'].\n",
    "\n",
    "    Take Hint (-30xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels =['FAKE', 'REAL'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the \"fake news\" model with TfidfVectorizer\n",
    "\n",
    "Now that you have evaluated the model using the CountVectorizer, you'll do the same using the TfidfVectorizer with a Naive Bayes model.\n",
    "\n",
    "The training and test sets have been created, and tfidf_vectorizer, tfidf_train, and tfidf_test have been computed. Additionally, MultinomialNB and metrics have been imported from, respectively, sklearn.naive_bayes and sklearn.\n",
    "Instructions\n",
    "\n",
    "   - Instantiate a MultinomialNB classifier called nb_classifier.\n",
    "   - Fit the classifier to the training data.\n",
    "   - Compute the predicted tags for the test data.\n",
    "   - Calculate and print the accuracy score of the classifier.\n",
    "   - Compute the confusion matrix. As in the previous exercise, specify the keyword argument labels=['FAKE', 'REAL'] so that the resulting confusion matrix is easier to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[\"FAKE\", \"REAL\"])\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NLP, complex problems - Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Improving the model\n",
    "\n",
    "What are possible next steps you could take to improve the model?\n",
    "Possible Answers\n",
    "\n",
    "    Tweaking alpha levels.\n",
    "    1\n",
    "    Trying a new classification model.\n",
    "    2\n",
    "    Training on a larger dataset.\n",
    "    3\n",
    "    Improving text preprocessing.\n",
    "    4\n",
    "    All of the above. (Correct)\n",
    "    5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Improving your model\n",
    "\n",
    "Your job in this exercise is to test a few different alpha levels using the Tfidf vectors to determine if there is a better performing combination.\n",
    "\n",
    "The training and test sets have been created, and tfidf_vectorizer, tfidf_train, and tfidf_test have been computed.\n",
    "Instructions\n",
    "\n",
    "   - Create a list of alphas to try using np.arange(). Values should range from 0 to 1 with steps of 0.1.\n",
    "   - Create a function train_and_predict() that takes in one argument: alpha. The function should:\n",
    "       - Instantiate a MultinomialNB classifier with alpha=alpha.\n",
    "       - Fit it to the training data.\n",
    "       - Compute predictions on the test data.\n",
    "       - Compute and return the accuracy score.\n",
    "   - Using a for loop, print the alpha, score and a newline in between. Use your train_and_predict() function to compute the score. Does the score change along with the alpha? What is the best alpha?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alphas):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alphas))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting your model\n",
    "\n",
    "Now that you have built a \"fake news\" classifier, you'll investigate what it has learned. You can map the important vector weights back to actual words using some simple inspection techniques.\n",
    "\n",
    "You have your well performing tfidf Naive Bayes classifier available as nb_classifier, and the vectors as tfidf_vectorizer.\n",
    "Instructions\n",
    "\n",
    "   - Save the class labels as class_labels by accessing the .classes_ attribute of nb_classifier.\n",
    "   - Extract the features using the .get_feature_names() method of tfidf_vectorizer.\n",
    "   - Create a zipped array of the classifier coefficients with the feature names and sort them by the coefficients. To do this, first use zip() with the arguments nb_classifier.coef_[0] and feature_names. Then, use sorted() on this.\n",
    "   - Print the top 20 weighted features for the first label of class_labels.\n",
    "   - Print the bottom 20 weighted features for the second label of class_labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0] , feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0][:20], feat_with_weights[:20])\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1][-20:], feat_with_weights[-20:])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
